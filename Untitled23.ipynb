{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Fkn0UxYTC3lAud8Kj6B4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaterynaSiniuta/DataMath/blob/main/Untitled23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install swig first (system dependency for box2d-py)\n",
        "!apt-get update && apt-get install -y swig\n",
        "\n",
        "# Then install the Python packages\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL_K5dCG0DQA",
        "outputId": "bc0dbe75-3e02-434d-df2c-109d1bad090a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [72.6 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,688 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,824 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,100 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,161 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Fetched 24.7 MB in 3s (7,973 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (763 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.13.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Collecting swig==4.* (from gymnasium[box2d])\n",
            "  Using cached swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Using cached swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2351181 sha256=b904fc6391e283a3d0e120b542e0212a6cb4c229d4257a54f0a29bc3d2b8ef1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: swig, box2d-py\n",
            "Successfully installed box2d-py-2.3.5 swig-4.3.0\n",
            "Collecting stable-baselines3[extra]\n",
            "  Using cached stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (4.13.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "# Create the environment\n",
        "env_id = \"LunarLander-v3\"\n",
        "n_envs = 16\n",
        "env = make_vec_env(env_id, n_envs=n_envs)\n",
        "\n",
        "# Create the evaluation envs\n",
        "eval_envs = make_vec_env(env_id, n_envs=5)\n",
        "\n",
        "# Adjust evaluation interval depending on the number of envs\n",
        "eval_freq = int(1e5)\n",
        "eval_freq = max(eval_freq // n_envs, 1)\n",
        "\n",
        "# Create evaluation callback to save best model\n",
        "# and monitor agent performance\n",
        "eval_callback = EvalCallback(\n",
        "    eval_envs,\n",
        "    best_model_save_path=\"./logs/\",\n",
        "    eval_freq=eval_freq,\n",
        "    n_eval_episodes=10,\n",
        ")\n",
        "\n",
        "# Instantiate the agent\n",
        "# Hyperparameters from https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    n_steps=1024,\n",
        "    batch_size=64,\n",
        "    gae_lambda=0.98,\n",
        "    gamma=0.999,\n",
        "    n_epochs=4,\n",
        "    ent_coef=0.01,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Train the agent (you can kill it before using ctrl+c)\n",
        "try:\n",
        "    model.learn(total_timesteps=int(5e6), callback=eval_callback)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "# Load best model\n",
        "model = PPO.load(\"logs/best_model.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQWnJvBU0GpX",
        "outputId": "700d0ee8-fbc0-42e3-9869-74911b2d85e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 301          |\n",
            "|    ep_rew_mean          | 260          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 715          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 1946         |\n",
            "|    total_timesteps      | 1392640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046748747 |\n",
            "|    clip_fraction        | 0.0653       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.671       |\n",
            "|    explained_variance   | 0.921        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 36.8         |\n",
            "|    n_updates            | 336          |\n",
            "|    policy_gradient_loss | -0.00142     |\n",
            "|    value_loss           | 207          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1400000, episode_reward=270.37 +/- 19.94\n",
            "Episode length: 297.80 +/- 14.73\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 298          |\n",
            "|    mean_reward          | 270          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1400000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038484372 |\n",
            "|    clip_fraction        | 0.0404       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.684       |\n",
            "|    explained_variance   | 0.921        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.9         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | 0.000518     |\n",
            "|    value_loss           | 161          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 301      |\n",
            "|    ep_rew_mean     | 259      |\n",
            "| time/              |          |\n",
            "|    fps             | 717      |\n",
            "|    iterations      | 86       |\n",
            "|    time_elapsed    | 1963     |\n",
            "|    total_timesteps | 1409024  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 304         |\n",
            "|    ep_rew_mean          | 257         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 719         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 1980        |\n",
            "|    total_timesteps      | 1425408     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003320814 |\n",
            "|    clip_fraction        | 0.0358      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.637      |\n",
            "|    explained_variance   | 0.928       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.5        |\n",
            "|    n_updates            | 344         |\n",
            "|    policy_gradient_loss | -0.000365   |\n",
            "|    value_loss           | 151         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 330          |\n",
            "|    ep_rew_mean          | 247          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 721          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 1997         |\n",
            "|    total_timesteps      | 1441792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043124836 |\n",
            "|    clip_fraction        | 0.0617       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.681       |\n",
            "|    explained_variance   | 0.949        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 91.6         |\n",
            "|    n_updates            | 348          |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    value_loss           | 167          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 337          |\n",
            "|    ep_rew_mean          | 248          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 724          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 2012         |\n",
            "|    total_timesteps      | 1458176      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039195986 |\n",
            "|    clip_fraction        | 0.0441       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.634       |\n",
            "|    explained_variance   | 0.943        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 270          |\n",
            "|    n_updates            | 352          |\n",
            "|    policy_gradient_loss | -0.000781    |\n",
            "|    value_loss           | 200          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 304          |\n",
            "|    ep_rew_mean          | 260          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 727          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 2026         |\n",
            "|    total_timesteps      | 1474560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040666913 |\n",
            "|    clip_fraction        | 0.0497       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.667       |\n",
            "|    explained_variance   | 0.974        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.06         |\n",
            "|    n_updates            | 356          |\n",
            "|    policy_gradient_loss | -8.87e-05    |\n",
            "|    value_loss           | 78.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 273          |\n",
            "|    ep_rew_mean          | 269          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 730          |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 2041         |\n",
            "|    total_timesteps      | 1490944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032606074 |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.688       |\n",
            "|    explained_variance   | 0.992        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.15         |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.000403    |\n",
            "|    value_loss           | 10.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1500000, episode_reward=268.55 +/- 18.52\n",
            "Episode length: 282.50 +/- 15.50\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 282         |\n",
            "|    mean_reward          | 269         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1500000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003025889 |\n",
            "|    clip_fraction        | 0.0368      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.687      |\n",
            "|    explained_variance   | 0.993       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.53        |\n",
            "|    n_updates            | 364         |\n",
            "|    policy_gradient_loss | 0.000867    |\n",
            "|    value_loss           | 9.71        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 270      |\n",
            "|    ep_rew_mean     | 269      |\n",
            "| time/              |          |\n",
            "|    fps             | 732      |\n",
            "|    iterations      | 92       |\n",
            "|    time_elapsed    | 2057     |\n",
            "|    total_timesteps | 1507328  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 270          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 735          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 2071         |\n",
            "|    total_timesteps      | 1523712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021568695 |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.658       |\n",
            "|    explained_variance   | 0.94         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.47         |\n",
            "|    n_updates            | 368          |\n",
            "|    policy_gradient_loss | 4.7e-05      |\n",
            "|    value_loss           | 135          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 288         |\n",
            "|    ep_rew_mean          | 267         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 738         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 2086        |\n",
            "|    total_timesteps      | 1540096     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003726823 |\n",
            "|    clip_fraction        | 0.0419      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.701      |\n",
            "|    explained_variance   | 0.964       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.06        |\n",
            "|    n_updates            | 372         |\n",
            "|    policy_gradient_loss | -0.000505   |\n",
            "|    value_loss           | 77.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 289          |\n",
            "|    ep_rew_mean          | 268          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 740          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 2100         |\n",
            "|    total_timesteps      | 1556480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038955691 |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.658       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.89         |\n",
            "|    n_updates            | 376          |\n",
            "|    policy_gradient_loss | -0.000623    |\n",
            "|    value_loss           | 9.15         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 300          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 743          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 2116         |\n",
            "|    total_timesteps      | 1572864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035099331 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.661       |\n",
            "|    explained_variance   | 0.948        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.2         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -8.94e-05    |\n",
            "|    value_loss           | 141          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 294          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 745          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 2130         |\n",
            "|    total_timesteps      | 1589248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034195387 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.669       |\n",
            "|    explained_variance   | 0.97         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.06         |\n",
            "|    n_updates            | 384          |\n",
            "|    policy_gradient_loss | -0.000538    |\n",
            "|    value_loss           | 75.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1600000, episode_reward=270.15 +/- 10.72\n",
            "Episode length: 283.40 +/- 11.86\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 283          |\n",
            "|    mean_reward          | 270          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1600000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038288333 |\n",
            "|    clip_fraction        | 0.0465       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.684       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.13         |\n",
            "|    n_updates            | 388          |\n",
            "|    policy_gradient_loss | 0.000589     |\n",
            "|    value_loss           | 10.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 280      |\n",
            "|    ep_rew_mean     | 269      |\n",
            "| time/              |          |\n",
            "|    fps             | 747      |\n",
            "|    iterations      | 98       |\n",
            "|    time_elapsed    | 2146     |\n",
            "|    total_timesteps | 1605632  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 272         |\n",
            "|    ep_rew_mean          | 271         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 750         |\n",
            "|    iterations           | 99          |\n",
            "|    time_elapsed         | 2160        |\n",
            "|    total_timesteps      | 1622016     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004298676 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.689      |\n",
            "|    explained_variance   | 0.966       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.77        |\n",
            "|    n_updates            | 392         |\n",
            "|    policy_gradient_loss | -0.000103   |\n",
            "|    value_loss           | 72.7        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 266        |\n",
            "|    ep_rew_mean          | 270        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 753        |\n",
            "|    iterations           | 100        |\n",
            "|    time_elapsed         | 2173       |\n",
            "|    total_timesteps      | 1638400    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00427781 |\n",
            "|    clip_fraction        | 0.0459     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.678     |\n",
            "|    explained_variance   | 0.996      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.61       |\n",
            "|    n_updates            | 396        |\n",
            "|    policy_gradient_loss | -9.6e-05   |\n",
            "|    value_loss           | 7.52       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 262         |\n",
            "|    ep_rew_mean          | 269         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 756         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 2187        |\n",
            "|    total_timesteps      | 1654784     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002247229 |\n",
            "|    clip_fraction        | 0.0297      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.673      |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.49        |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | 0.000815    |\n",
            "|    value_loss           | 71          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 267          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 759          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 2201         |\n",
            "|    total_timesteps      | 1671168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040080715 |\n",
            "|    clip_fraction        | 0.0321       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.66        |\n",
            "|    explained_variance   | 0.947        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 280          |\n",
            "|    n_updates            | 404          |\n",
            "|    policy_gradient_loss | -0.000587    |\n",
            "|    value_loss           | 129          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 289          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 761          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 2216         |\n",
            "|    total_timesteps      | 1687552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037305062 |\n",
            "|    clip_fraction        | 0.0384       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.681       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.7         |\n",
            "|    n_updates            | 408          |\n",
            "|    policy_gradient_loss | 0.000211     |\n",
            "|    value_loss           | 10.5         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1700000, episode_reward=258.79 +/- 20.75\n",
            "Episode length: 279.20 +/- 16.33\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 279          |\n",
            "|    mean_reward          | 259          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1700000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039223805 |\n",
            "|    clip_fraction        | 0.0463       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.689       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.2          |\n",
            "|    n_updates            | 412          |\n",
            "|    policy_gradient_loss | 0.000377     |\n",
            "|    value_loss           | 6.3          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 287      |\n",
            "|    ep_rew_mean     | 273      |\n",
            "| time/              |          |\n",
            "|    fps             | 763      |\n",
            "|    iterations      | 104      |\n",
            "|    time_elapsed    | 2232     |\n",
            "|    total_timesteps | 1703936  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 279          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 765          |\n",
            "|    iterations           | 105          |\n",
            "|    time_elapsed         | 2246         |\n",
            "|    total_timesteps      | 1720320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033485736 |\n",
            "|    clip_fraction        | 0.0329       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.676       |\n",
            "|    explained_variance   | 0.974        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.28         |\n",
            "|    n_updates            | 416          |\n",
            "|    policy_gradient_loss | 0.000777     |\n",
            "|    value_loss           | 67.7         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 271         |\n",
            "|    ep_rew_mean          | 267         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 768         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 2259        |\n",
            "|    total_timesteps      | 1736704     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004154542 |\n",
            "|    clip_fraction        | 0.0361      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.687      |\n",
            "|    explained_variance   | 0.952       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 165         |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.000557   |\n",
            "|    value_loss           | 132         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 261         |\n",
            "|    ep_rew_mean          | 274         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 771         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 2273        |\n",
            "|    total_timesteps      | 1753088     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004445248 |\n",
            "|    clip_fraction        | 0.0426      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.68       |\n",
            "|    explained_variance   | 0.944       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 129         |\n",
            "|    n_updates            | 424         |\n",
            "|    policy_gradient_loss | 2.46e-05    |\n",
            "|    value_loss           | 130         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 265         |\n",
            "|    ep_rew_mean          | 271         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 773         |\n",
            "|    iterations           | 108         |\n",
            "|    time_elapsed         | 2286        |\n",
            "|    total_timesteps      | 1769472     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004248093 |\n",
            "|    clip_fraction        | 0.0496      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.709      |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.72        |\n",
            "|    n_updates            | 428         |\n",
            "|    policy_gradient_loss | -0.000104   |\n",
            "|    value_loss           | 6.51        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 260          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 775          |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 2301         |\n",
            "|    total_timesteps      | 1785856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030460362 |\n",
            "|    clip_fraction        | 0.0369       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.673       |\n",
            "|    explained_variance   | 0.971        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.46         |\n",
            "|    n_updates            | 432          |\n",
            "|    policy_gradient_loss | -5.4e-05     |\n",
            "|    value_loss           | 67.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1800000, episode_reward=278.73 +/- 21.28\n",
            "Episode length: 275.40 +/- 12.25\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 275          |\n",
            "|    mean_reward          | 279          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1800000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035707038 |\n",
            "|    clip_fraction        | 0.0442       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.664       |\n",
            "|    explained_variance   | 0.962        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 218          |\n",
            "|    n_updates            | 436          |\n",
            "|    policy_gradient_loss | 0.000404     |\n",
            "|    value_loss           | 90.9         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 256      |\n",
            "|    ep_rew_mean     | 271      |\n",
            "| time/              |          |\n",
            "|    fps             | 777      |\n",
            "|    iterations      | 110      |\n",
            "|    time_elapsed    | 2318     |\n",
            "|    total_timesteps | 1802240  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 267          |\n",
            "|    ep_rew_mean          | 268          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 779          |\n",
            "|    iterations           | 111          |\n",
            "|    time_elapsed         | 2331         |\n",
            "|    total_timesteps      | 1818624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039248634 |\n",
            "|    clip_fraction        | 0.0416       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.668       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.07         |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | 0.000367     |\n",
            "|    value_loss           | 5.21         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 259          |\n",
            "|    ep_rew_mean          | 264          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 782          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 2344         |\n",
            "|    total_timesteps      | 1835008      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031616369 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.681       |\n",
            "|    explained_variance   | 0.946        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.95         |\n",
            "|    n_updates            | 444          |\n",
            "|    policy_gradient_loss | 0.000168     |\n",
            "|    value_loss           | 137          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 253          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 785          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 2358         |\n",
            "|    total_timesteps      | 1851392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022931017 |\n",
            "|    clip_fraction        | 0.022        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.643       |\n",
            "|    explained_variance   | 0.925        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.16         |\n",
            "|    n_updates            | 448          |\n",
            "|    policy_gradient_loss | 0.000379     |\n",
            "|    value_loss           | 197          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 254         |\n",
            "|    ep_rew_mean          | 274         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 787         |\n",
            "|    iterations           | 114         |\n",
            "|    time_elapsed         | 2372        |\n",
            "|    total_timesteps      | 1867776     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004375068 |\n",
            "|    clip_fraction        | 0.0513      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.664      |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.41        |\n",
            "|    n_updates            | 452         |\n",
            "|    policy_gradient_loss | 0.000568    |\n",
            "|    value_loss           | 4.43        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 277         |\n",
            "|    ep_rew_mean          | 274         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 789         |\n",
            "|    iterations           | 115         |\n",
            "|    time_elapsed         | 2385        |\n",
            "|    total_timesteps      | 1884160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003521812 |\n",
            "|    clip_fraction        | 0.0307      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.647      |\n",
            "|    explained_variance   | 0.974       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.14        |\n",
            "|    n_updates            | 456         |\n",
            "|    policy_gradient_loss | -0.000735   |\n",
            "|    value_loss           | 55.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1900000, episode_reward=271.18 +/- 23.82\n",
            "Episode length: 271.60 +/- 15.54\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 272         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1900000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003947908 |\n",
            "|    clip_fraction        | 0.049       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.656      |\n",
            "|    explained_variance   | 0.975       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.7         |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.000538   |\n",
            "|    value_loss           | 73.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 260      |\n",
            "|    ep_rew_mean     | 272      |\n",
            "| time/              |          |\n",
            "|    fps             | 791      |\n",
            "|    iterations      | 116      |\n",
            "|    time_elapsed    | 2399     |\n",
            "|    total_timesteps | 1900544  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 257          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 794          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 2413         |\n",
            "|    total_timesteps      | 1916928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038633589 |\n",
            "|    clip_fraction        | 0.035        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.666       |\n",
            "|    explained_variance   | 0.974        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.97         |\n",
            "|    n_updates            | 464          |\n",
            "|    policy_gradient_loss | 0.00066      |\n",
            "|    value_loss           | 62.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 255         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 796         |\n",
            "|    iterations           | 118         |\n",
            "|    time_elapsed         | 2426        |\n",
            "|    total_timesteps      | 1933312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002992306 |\n",
            "|    clip_fraction        | 0.0304      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.666      |\n",
            "|    explained_variance   | 0.953       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 191         |\n",
            "|    n_updates            | 468         |\n",
            "|    policy_gradient_loss | 0.000664    |\n",
            "|    value_loss           | 125         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 252         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 798         |\n",
            "|    iterations           | 119         |\n",
            "|    time_elapsed         | 2441        |\n",
            "|    total_timesteps      | 1949696     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003700856 |\n",
            "|    clip_fraction        | 0.0365      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.636      |\n",
            "|    explained_variance   | 0.949       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.37        |\n",
            "|    n_updates            | 472         |\n",
            "|    policy_gradient_loss | 0.000499    |\n",
            "|    value_loss           | 136         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 247          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 2454         |\n",
            "|    total_timesteps      | 1966080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042922157 |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.669       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.24         |\n",
            "|    n_updates            | 476          |\n",
            "|    policy_gradient_loss | 0.00108      |\n",
            "|    value_loss           | 4.46         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 249          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 803          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 2467         |\n",
            "|    total_timesteps      | 1982464      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016438074 |\n",
            "|    clip_fraction        | 0.00803      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.625       |\n",
            "|    explained_variance   | 0.875        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 358          |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.000416    |\n",
            "|    value_loss           | 359          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 251         |\n",
            "|    ep_rew_mean          | 273         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 805         |\n",
            "|    iterations           | 122         |\n",
            "|    time_elapsed         | 2480        |\n",
            "|    total_timesteps      | 1998848     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002790141 |\n",
            "|    clip_fraction        | 0.0337      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.626      |\n",
            "|    explained_variance   | 0.955       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 178         |\n",
            "|    n_updates            | 484         |\n",
            "|    policy_gradient_loss | 0.00023     |\n",
            "|    value_loss           | 125         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=2000000, episode_reward=268.81 +/- 12.75\n",
            "Episode length: 252.80 +/- 11.87\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 253          |\n",
            "|    mean_reward          | 269          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2000000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040652007 |\n",
            "|    clip_fraction        | 0.0445       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.631       |\n",
            "|    explained_variance   | 0.948        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 109          |\n",
            "|    n_updates            | 488          |\n",
            "|    policy_gradient_loss | 0.00076      |\n",
            "|    value_loss           | 143          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 246      |\n",
            "|    ep_rew_mean     | 263      |\n",
            "| time/              |          |\n",
            "|    fps             | 807      |\n",
            "|    iterations      | 123      |\n",
            "|    time_elapsed    | 2495     |\n",
            "|    total_timesteps | 2015232  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 248          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 810          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 2508         |\n",
            "|    total_timesteps      | 2031616      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026088185 |\n",
            "|    clip_fraction        | 0.0281       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.652       |\n",
            "|    explained_variance   | 0.895        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 211          |\n",
            "|    n_updates            | 492          |\n",
            "|    policy_gradient_loss | -0.000457    |\n",
            "|    value_loss           | 291          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 246          |\n",
            "|    ep_rew_mean          | 269          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 812          |\n",
            "|    iterations           | 125          |\n",
            "|    time_elapsed         | 2521         |\n",
            "|    total_timesteps      | 2048000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038401724 |\n",
            "|    clip_fraction        | 0.0459       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.636       |\n",
            "|    explained_variance   | 0.926        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 45.9         |\n",
            "|    n_updates            | 496          |\n",
            "|    policy_gradient_loss | 0.000345     |\n",
            "|    value_loss           | 215          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 246         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 814         |\n",
            "|    iterations           | 126         |\n",
            "|    time_elapsed         | 2534        |\n",
            "|    total_timesteps      | 2064384     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005139401 |\n",
            "|    clip_fraction        | 0.0605      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.649      |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 22          |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | -0.000484   |\n",
            "|    value_loss           | 72          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 242          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 816          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 2548         |\n",
            "|    total_timesteps      | 2080768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033203457 |\n",
            "|    clip_fraction        | 0.043        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.641       |\n",
            "|    explained_variance   | 0.97         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 149          |\n",
            "|    n_updates            | 504          |\n",
            "|    policy_gradient_loss | 0.000471     |\n",
            "|    value_loss           | 73.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 252         |\n",
            "|    ep_rew_mean          | 269         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 818         |\n",
            "|    iterations           | 128         |\n",
            "|    time_elapsed         | 2562        |\n",
            "|    total_timesteps      | 2097152     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002471616 |\n",
            "|    clip_fraction        | 0.0262      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | 0.929       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 243         |\n",
            "|    n_updates            | 508         |\n",
            "|    policy_gradient_loss | -4.32e-05   |\n",
            "|    value_loss           | 171         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=2100000, episode_reward=266.39 +/- 20.74\n",
            "Episode length: 262.90 +/- 13.28\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 263          |\n",
            "|    mean_reward          | 266          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2100000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045594913 |\n",
            "|    clip_fraction        | 0.0512       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.671       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.53         |\n",
            "|    n_updates            | 512          |\n",
            "|    policy_gradient_loss | 0.000607     |\n",
            "|    value_loss           | 6.05         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 254      |\n",
            "|    ep_rew_mean     | 277      |\n",
            "| time/              |          |\n",
            "|    fps             | 820      |\n",
            "|    iterations      | 129      |\n",
            "|    time_elapsed    | 2577     |\n",
            "|    total_timesteps | 2113536  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 250          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 822          |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 2590         |\n",
            "|    total_timesteps      | 2129920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044084936 |\n",
            "|    clip_fraction        | 0.0466       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.64        |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.56         |\n",
            "|    n_updates            | 516          |\n",
            "|    policy_gradient_loss | 0.000479     |\n",
            "|    value_loss           | 4.32         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 248         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 824         |\n",
            "|    iterations           | 131         |\n",
            "|    time_elapsed         | 2604        |\n",
            "|    total_timesteps      | 2146304     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003691677 |\n",
            "|    clip_fraction        | 0.0479      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.667      |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.2         |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -4.42e-05   |\n",
            "|    value_loss           | 4.09        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 246         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 826         |\n",
            "|    iterations           | 132         |\n",
            "|    time_elapsed         | 2617        |\n",
            "|    total_timesteps      | 2162688     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003776998 |\n",
            "|    clip_fraction        | 0.0485      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.655      |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.58        |\n",
            "|    n_updates            | 524         |\n",
            "|    policy_gradient_loss | -0.000343   |\n",
            "|    value_loss           | 3.7         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 242          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 2630         |\n",
            "|    total_timesteps      | 2179072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038098204 |\n",
            "|    clip_fraction        | 0.0369       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.642       |\n",
            "|    explained_variance   | 0.993        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.36         |\n",
            "|    n_updates            | 528          |\n",
            "|    policy_gradient_loss | -6.1e-05     |\n",
            "|    value_loss           | 17.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 830          |\n",
            "|    iterations           | 134          |\n",
            "|    time_elapsed         | 2642         |\n",
            "|    total_timesteps      | 2195456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028776126 |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.642       |\n",
            "|    explained_variance   | 0.95         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 142          |\n",
            "|    n_updates            | 532          |\n",
            "|    policy_gradient_loss | 0.000444     |\n",
            "|    value_loss           | 137          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2200000, episode_reward=272.22 +/- 18.57\n",
            "Episode length: 250.30 +/- 14.93\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 250          |\n",
            "|    mean_reward          | 272          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2200000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030695745 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.655       |\n",
            "|    explained_variance   | 0.933        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 22.9         |\n",
            "|    n_updates            | 536          |\n",
            "|    policy_gradient_loss | -2.09e-05    |\n",
            "|    value_loss           | 207          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 251      |\n",
            "|    ep_rew_mean     | 270      |\n",
            "| time/              |          |\n",
            "|    fps             | 832      |\n",
            "|    iterations      | 135      |\n",
            "|    time_elapsed    | 2658     |\n",
            "|    total_timesteps | 2211840  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 253          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 834          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 2671         |\n",
            "|    total_timesteps      | 2228224      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041681435 |\n",
            "|    clip_fraction        | 0.0446       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.671       |\n",
            "|    explained_variance   | 0.95         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 11.4         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -7.22e-05    |\n",
            "|    value_loss           | 141          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 246          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 137          |\n",
            "|    time_elapsed         | 2683         |\n",
            "|    total_timesteps      | 2244608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030734322 |\n",
            "|    clip_fraction        | 0.04         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.632       |\n",
            "|    explained_variance   | 0.954        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 61.7         |\n",
            "|    n_updates            | 544          |\n",
            "|    policy_gradient_loss | 0.000603     |\n",
            "|    value_loss           | 127          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 243         |\n",
            "|    ep_rew_mean          | 280         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 838         |\n",
            "|    iterations           | 138         |\n",
            "|    time_elapsed         | 2696        |\n",
            "|    total_timesteps      | 2260992     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004272219 |\n",
            "|    clip_fraction        | 0.0664      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.634      |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.54        |\n",
            "|    n_updates            | 548         |\n",
            "|    policy_gradient_loss | -7.93e-05   |\n",
            "|    value_loss           | 4.56        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 243         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 840         |\n",
            "|    iterations           | 139         |\n",
            "|    time_elapsed         | 2710        |\n",
            "|    total_timesteps      | 2277376     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004215037 |\n",
            "|    clip_fraction        | 0.0491      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.66       |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.917       |\n",
            "|    n_updates            | 552         |\n",
            "|    policy_gradient_loss | 0.000179    |\n",
            "|    value_loss           | 2.67        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 260          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 842          |\n",
            "|    iterations           | 140          |\n",
            "|    time_elapsed         | 2723         |\n",
            "|    total_timesteps      | 2293760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035837204 |\n",
            "|    clip_fraction        | 0.04         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.647       |\n",
            "|    explained_variance   | 0.956        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 147          |\n",
            "|    n_updates            | 556          |\n",
            "|    policy_gradient_loss | -0.00073     |\n",
            "|    value_loss           | 130          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2300000, episode_reward=273.14 +/- 17.82\n",
            "Episode length: 243.60 +/- 18.59\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 244          |\n",
            "|    mean_reward          | 273          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2300000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037639542 |\n",
            "|    clip_fraction        | 0.0383       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.657       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24         |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | 0.000911     |\n",
            "|    value_loss           | 4.06         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 248      |\n",
            "|    ep_rew_mean     | 277      |\n",
            "| time/              |          |\n",
            "|    fps             | 843      |\n",
            "|    iterations      | 141      |\n",
            "|    time_elapsed    | 2738     |\n",
            "|    total_timesteps | 2310144  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 244          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 845          |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 2751         |\n",
            "|    total_timesteps      | 2326528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038800414 |\n",
            "|    clip_fraction        | 0.0366       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.644       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.37         |\n",
            "|    n_updates            | 564          |\n",
            "|    policy_gradient_loss | 0.000152     |\n",
            "|    value_loss           | 3.36         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 847          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 2764         |\n",
            "|    total_timesteps      | 2342912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033307774 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.645       |\n",
            "|    explained_variance   | 0.954        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.7         |\n",
            "|    n_updates            | 568          |\n",
            "|    policy_gradient_loss | -0.000649    |\n",
            "|    value_loss           | 128          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 236         |\n",
            "|    ep_rew_mean          | 262         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 849         |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 2777        |\n",
            "|    total_timesteps      | 2359296     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003781153 |\n",
            "|    clip_fraction        | 0.0283      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.624      |\n",
            "|    explained_variance   | 0.941       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.9        |\n",
            "|    n_updates            | 572         |\n",
            "|    policy_gradient_loss | 0.000135    |\n",
            "|    value_loss           | 178         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 850          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 2791         |\n",
            "|    total_timesteps      | 2375680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037981924 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.622       |\n",
            "|    explained_variance   | 0.878        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 114          |\n",
            "|    n_updates            | 576          |\n",
            "|    policy_gradient_loss | -0.000607    |\n",
            "|    value_loss           | 389          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 852          |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 2804         |\n",
            "|    total_timesteps      | 2392064      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036219202 |\n",
            "|    clip_fraction        | 0.0362       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.621       |\n",
            "|    explained_variance   | 0.959        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 11.9         |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | 0.000996     |\n",
            "|    value_loss           | 118          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2400000, episode_reward=281.50 +/- 15.72\n",
            "Episode length: 240.40 +/- 15.69\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 240          |\n",
            "|    mean_reward          | 281          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2400000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042673927 |\n",
            "|    clip_fraction        | 0.0409       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | 0.906        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 70.7         |\n",
            "|    n_updates            | 584          |\n",
            "|    policy_gradient_loss | -0.000988    |\n",
            "|    value_loss           | 251          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 235      |\n",
            "|    ep_rew_mean     | 259      |\n",
            "| time/              |          |\n",
            "|    fps             | 854      |\n",
            "|    iterations      | 147      |\n",
            "|    time_elapsed    | 2818     |\n",
            "|    total_timesteps | 2408448  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 229         |\n",
            "|    ep_rew_mean          | 261         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 856         |\n",
            "|    iterations           | 148         |\n",
            "|    time_elapsed         | 2832        |\n",
            "|    total_timesteps      | 2424832     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002574121 |\n",
            "|    clip_fraction        | 0.0286      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.635      |\n",
            "|    explained_variance   | 0.866       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 27          |\n",
            "|    n_updates            | 588         |\n",
            "|    policy_gradient_loss | -0.000325   |\n",
            "|    value_loss           | 232         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 234          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 857          |\n",
            "|    iterations           | 149          |\n",
            "|    time_elapsed         | 2845         |\n",
            "|    total_timesteps      | 2441216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023274843 |\n",
            "|    clip_fraction        | 0.0283       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.615       |\n",
            "|    explained_variance   | 0.885        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 104          |\n",
            "|    n_updates            | 592          |\n",
            "|    policy_gradient_loss | 0.000168     |\n",
            "|    value_loss           | 333          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 241          |\n",
            "|    ep_rew_mean          | 273          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 859          |\n",
            "|    iterations           | 150          |\n",
            "|    time_elapsed         | 2859         |\n",
            "|    total_timesteps      | 2457600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039804834 |\n",
            "|    clip_fraction        | 0.0568       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.638       |\n",
            "|    explained_variance   | 0.944        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 315          |\n",
            "|    n_updates            | 596          |\n",
            "|    policy_gradient_loss | 0.00024      |\n",
            "|    value_loss           | 138          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 242          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 861          |\n",
            "|    iterations           | 151          |\n",
            "|    time_elapsed         | 2871         |\n",
            "|    total_timesteps      | 2473984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040647127 |\n",
            "|    clip_fraction        | 0.0477       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.621       |\n",
            "|    explained_variance   | 0.973        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.39         |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | 0.00109      |\n",
            "|    value_loss           | 65.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 235         |\n",
            "|    ep_rew_mean          | 264         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 863         |\n",
            "|    iterations           | 152         |\n",
            "|    time_elapsed         | 2884        |\n",
            "|    total_timesteps      | 2490368     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005069273 |\n",
            "|    clip_fraction        | 0.0393      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.669      |\n",
            "|    explained_variance   | 0.965       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 28.2        |\n",
            "|    n_updates            | 604         |\n",
            "|    policy_gradient_loss | 0.000977    |\n",
            "|    value_loss           | 69          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=2500000, episode_reward=281.53 +/- 12.34\n",
            "Episode length: 245.30 +/- 14.33\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 245          |\n",
            "|    mean_reward          | 282          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2500000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036179735 |\n",
            "|    clip_fraction        | 0.0356       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.63        |\n",
            "|    explained_variance   | 0.908        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 28.2         |\n",
            "|    n_updates            | 608          |\n",
            "|    policy_gradient_loss | -0.000135    |\n",
            "|    value_loss           | 206          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 236      |\n",
            "|    ep_rew_mean     | 272      |\n",
            "| time/              |          |\n",
            "|    fps             | 864      |\n",
            "|    iterations      | 153      |\n",
            "|    time_elapsed    | 2899     |\n",
            "|    total_timesteps | 2506752  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 866          |\n",
            "|    iterations           | 154          |\n",
            "|    time_elapsed         | 2912         |\n",
            "|    total_timesteps      | 2523136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037118264 |\n",
            "|    clip_fraction        | 0.0462       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.602       |\n",
            "|    explained_variance   | 0.946        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.1         |\n",
            "|    n_updates            | 612          |\n",
            "|    policy_gradient_loss | 0.000226     |\n",
            "|    value_loss           | 147          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 237         |\n",
            "|    ep_rew_mean          | 261         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 868         |\n",
            "|    iterations           | 155         |\n",
            "|    time_elapsed         | 2924        |\n",
            "|    total_timesteps      | 2539520     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003688314 |\n",
            "|    clip_fraction        | 0.0407      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.641      |\n",
            "|    explained_variance   | 0.904       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 213         |\n",
            "|    n_updates            | 616         |\n",
            "|    policy_gradient_loss | -0.00046    |\n",
            "|    value_loss           | 223         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 264          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 870          |\n",
            "|    iterations           | 156          |\n",
            "|    time_elapsed         | 2937         |\n",
            "|    total_timesteps      | 2555904      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028917054 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.627       |\n",
            "|    explained_variance   | 0.888        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 59.4         |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.000219    |\n",
            "|    value_loss           | 375          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 235         |\n",
            "|    ep_rew_mean          | 269         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 871         |\n",
            "|    iterations           | 157         |\n",
            "|    time_elapsed         | 2950        |\n",
            "|    total_timesteps      | 2572288     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005006439 |\n",
            "|    clip_fraction        | 0.0462      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.633      |\n",
            "|    explained_variance   | 0.906       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 56          |\n",
            "|    n_updates            | 624         |\n",
            "|    policy_gradient_loss | 0.000137    |\n",
            "|    value_loss           | 275         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 235         |\n",
            "|    ep_rew_mean          | 273         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 873         |\n",
            "|    iterations           | 158         |\n",
            "|    time_elapsed         | 2964        |\n",
            "|    total_timesteps      | 2588672     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004520519 |\n",
            "|    clip_fraction        | 0.0534      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.618      |\n",
            "|    explained_variance   | 0.944       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 173         |\n",
            "|    n_updates            | 628         |\n",
            "|    policy_gradient_loss | 0.0003      |\n",
            "|    value_loss           | 104         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=2600000, episode_reward=258.29 +/- 60.29\n",
            "Episode length: 235.70 +/- 30.27\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 236          |\n",
            "|    mean_reward          | 258          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2600000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029057607 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.613       |\n",
            "|    explained_variance   | 0.929        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.48         |\n",
            "|    n_updates            | 632          |\n",
            "|    policy_gradient_loss | -0.000829    |\n",
            "|    value_loss           | 182          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 240      |\n",
            "|    ep_rew_mean     | 268      |\n",
            "| time/              |          |\n",
            "|    fps             | 874      |\n",
            "|    iterations      | 159      |\n",
            "|    time_elapsed    | 2979     |\n",
            "|    total_timesteps | 2605056  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 241         |\n",
            "|    ep_rew_mean          | 268         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 876         |\n",
            "|    iterations           | 160         |\n",
            "|    time_elapsed         | 2992        |\n",
            "|    total_timesteps      | 2621440     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004115667 |\n",
            "|    clip_fraction        | 0.0361      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.627      |\n",
            "|    explained_variance   | 0.92        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 54.6        |\n",
            "|    n_updates            | 636         |\n",
            "|    policy_gradient_loss | -0.00037    |\n",
            "|    value_loss           | 195         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 242          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 877          |\n",
            "|    iterations           | 161          |\n",
            "|    time_elapsed         | 3004         |\n",
            "|    total_timesteps      | 2637824      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057433555 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.61        |\n",
            "|    explained_variance   | 0.949        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 20.9         |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.000432    |\n",
            "|    value_loss           | 106          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 240         |\n",
            "|    ep_rew_mean          | 261         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 879         |\n",
            "|    iterations           | 162         |\n",
            "|    time_elapsed         | 3017        |\n",
            "|    total_timesteps      | 2654208     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004459995 |\n",
            "|    clip_fraction        | 0.0392      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.624      |\n",
            "|    explained_variance   | 0.922       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 43.2        |\n",
            "|    n_updates            | 644         |\n",
            "|    policy_gradient_loss | -0.000208   |\n",
            "|    value_loss           | 217         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 241          |\n",
            "|    ep_rew_mean          | 263          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 881          |\n",
            "|    iterations           | 163          |\n",
            "|    time_elapsed         | 3030         |\n",
            "|    total_timesteps      | 2670592      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035592648 |\n",
            "|    clip_fraction        | 0.0353       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.616       |\n",
            "|    explained_variance   | 0.919        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 138          |\n",
            "|    n_updates            | 648          |\n",
            "|    policy_gradient_loss | 0.000624     |\n",
            "|    value_loss           | 194          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 244          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 882          |\n",
            "|    iterations           | 164          |\n",
            "|    time_elapsed         | 3044         |\n",
            "|    total_timesteps      | 2686976      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033625183 |\n",
            "|    clip_fraction        | 0.032        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0.939        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 21.5         |\n",
            "|    n_updates            | 652          |\n",
            "|    policy_gradient_loss | 0.00034      |\n",
            "|    value_loss           | 167          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2700000, episode_reward=281.20 +/- 14.42\n",
            "Episode length: 247.00 +/- 19.10\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 247         |\n",
            "|    mean_reward          | 281         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 2700000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004285971 |\n",
            "|    clip_fraction        | 0.0381      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.635      |\n",
            "|    explained_variance   | 0.933       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.5        |\n",
            "|    n_updates            | 656         |\n",
            "|    policy_gradient_loss | 0.000929    |\n",
            "|    value_loss           | 222         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 254      |\n",
            "|    ep_rew_mean     | 268      |\n",
            "| time/              |          |\n",
            "|    fps             | 883      |\n",
            "|    iterations      | 165      |\n",
            "|    time_elapsed    | 3058     |\n",
            "|    total_timesteps | 2703360  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 246          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 885          |\n",
            "|    iterations           | 166          |\n",
            "|    time_elapsed         | 3071         |\n",
            "|    total_timesteps      | 2719744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039195516 |\n",
            "|    clip_fraction        | 0.0499       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.619       |\n",
            "|    explained_variance   | 0.948        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 325          |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | 0.000712     |\n",
            "|    value_loss           | 155          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 240          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 887          |\n",
            "|    iterations           | 167          |\n",
            "|    time_elapsed         | 3084         |\n",
            "|    total_timesteps      | 2736128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034670457 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.66        |\n",
            "|    explained_variance   | 0.947        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.62         |\n",
            "|    n_updates            | 664          |\n",
            "|    policy_gradient_loss | 0.00123      |\n",
            "|    value_loss           | 132          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 253          |\n",
            "|    ep_rew_mean          | 280          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 888          |\n",
            "|    iterations           | 168          |\n",
            "|    time_elapsed         | 3097         |\n",
            "|    total_timesteps      | 2752512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048531103 |\n",
            "|    clip_fraction        | 0.0611       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.634       |\n",
            "|    explained_variance   | 0.994        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.2          |\n",
            "|    n_updates            | 668          |\n",
            "|    policy_gradient_loss | 0.00022      |\n",
            "|    value_loss           | 8.48         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 244          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 890          |\n",
            "|    iterations           | 169          |\n",
            "|    time_elapsed         | 3110         |\n",
            "|    total_timesteps      | 2768896      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034789068 |\n",
            "|    clip_fraction        | 0.0414       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.627       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.7          |\n",
            "|    n_updates            | 672          |\n",
            "|    policy_gradient_loss | 0.000647     |\n",
            "|    value_loss           | 4.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 240          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 891          |\n",
            "|    iterations           | 170          |\n",
            "|    time_elapsed         | 3123         |\n",
            "|    total_timesteps      | 2785280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044823214 |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.656       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.4          |\n",
            "|    n_updates            | 676          |\n",
            "|    policy_gradient_loss | -0.000666    |\n",
            "|    value_loss           | 3.44         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2800000, episode_reward=273.66 +/- 20.83\n",
            "Episode length: 249.90 +/- 12.91\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 250          |\n",
            "|    mean_reward          | 274          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2800000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021905308 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.652       |\n",
            "|    explained_variance   | 0.94         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 14.3         |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -1.77e-05    |\n",
            "|    value_loss           | 151          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 236      |\n",
            "|    ep_rew_mean     | 269      |\n",
            "| time/              |          |\n",
            "|    fps             | 892      |\n",
            "|    iterations      | 171      |\n",
            "|    time_elapsed    | 3137     |\n",
            "|    total_timesteps | 2801664  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 231          |\n",
            "|    ep_rew_mean          | 269          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 894          |\n",
            "|    iterations           | 172          |\n",
            "|    time_elapsed         | 3151         |\n",
            "|    total_timesteps      | 2818048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028736698 |\n",
            "|    clip_fraction        | 0.0122       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0.905        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 96.8         |\n",
            "|    n_updates            | 684          |\n",
            "|    policy_gradient_loss | -0.000193    |\n",
            "|    value_loss           | 244          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 229         |\n",
            "|    ep_rew_mean          | 260         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 895         |\n",
            "|    iterations           | 173         |\n",
            "|    time_elapsed         | 3164        |\n",
            "|    total_timesteps      | 2834432     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004079075 |\n",
            "|    clip_fraction        | 0.0474      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.659      |\n",
            "|    explained_variance   | 0.939       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.2        |\n",
            "|    n_updates            | 688         |\n",
            "|    policy_gradient_loss | 0.000119    |\n",
            "|    value_loss           | 140         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 230         |\n",
            "|    ep_rew_mean          | 265         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 897         |\n",
            "|    iterations           | 174         |\n",
            "|    time_elapsed         | 3176        |\n",
            "|    total_timesteps      | 2850816     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002413748 |\n",
            "|    clip_fraction        | 0.0128      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.645      |\n",
            "|    explained_variance   | 0.874       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 32.9        |\n",
            "|    n_updates            | 692         |\n",
            "|    policy_gradient_loss | -0.000322   |\n",
            "|    value_loss           | 389         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 248          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 898          |\n",
            "|    iterations           | 175          |\n",
            "|    time_elapsed         | 3189         |\n",
            "|    total_timesteps      | 2867200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035912723 |\n",
            "|    clip_fraction        | 0.0469       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.609       |\n",
            "|    explained_variance   | 0.96         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.6          |\n",
            "|    n_updates            | 696          |\n",
            "|    policy_gradient_loss | 0.000538     |\n",
            "|    value_loss           | 109          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 240          |\n",
            "|    ep_rew_mean          | 262          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 900          |\n",
            "|    iterations           | 176          |\n",
            "|    time_elapsed         | 3203         |\n",
            "|    total_timesteps      | 2883584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029752832 |\n",
            "|    clip_fraction        | 0.0356       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.62        |\n",
            "|    explained_variance   | 0.96         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 15.6         |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | 0.00101      |\n",
            "|    value_loss           | 80           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 244         |\n",
            "|    ep_rew_mean          | 268         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 901         |\n",
            "|    iterations           | 177         |\n",
            "|    time_elapsed         | 3216        |\n",
            "|    total_timesteps      | 2899968     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004490451 |\n",
            "|    clip_fraction        | 0.0393      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.617      |\n",
            "|    explained_variance   | 0.932       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 241         |\n",
            "|    n_updates            | 704         |\n",
            "|    policy_gradient_loss | 1.63e-05    |\n",
            "|    value_loss           | 257         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=2900000, episode_reward=279.19 +/- 38.34\n",
            "Episode length: 320.30 +/- 227.59\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 320          |\n",
            "|    mean_reward          | 279          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2900000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040814923 |\n",
            "|    clip_fraction        | 0.0622       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.621       |\n",
            "|    explained_variance   | 0.967        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.94         |\n",
            "|    n_updates            | 708          |\n",
            "|    policy_gradient_loss | 0.000594     |\n",
            "|    value_loss           | 74.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 239      |\n",
            "|    ep_rew_mean     | 277      |\n",
            "| time/              |          |\n",
            "|    fps             | 902      |\n",
            "|    iterations      | 178      |\n",
            "|    time_elapsed    | 3232     |\n",
            "|    total_timesteps | 2916352  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 903          |\n",
            "|    iterations           | 179          |\n",
            "|    time_elapsed         | 3245         |\n",
            "|    total_timesteps      | 2932736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042562033 |\n",
            "|    clip_fraction        | 0.0428       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0.98         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.65         |\n",
            "|    n_updates            | 712          |\n",
            "|    policy_gradient_loss | 0.000318     |\n",
            "|    value_loss           | 36.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 229          |\n",
            "|    ep_rew_mean          | 258          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 905          |\n",
            "|    iterations           | 180          |\n",
            "|    time_elapsed         | 3257         |\n",
            "|    total_timesteps      | 2949120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029308684 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.616       |\n",
            "|    explained_variance   | 0.932        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 116          |\n",
            "|    n_updates            | 716          |\n",
            "|    policy_gradient_loss | 0.000819     |\n",
            "|    value_loss           | 189          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 230          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 906          |\n",
            "|    iterations           | 181          |\n",
            "|    time_elapsed         | 3270         |\n",
            "|    total_timesteps      | 2965504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020180843 |\n",
            "|    clip_fraction        | 0.0231       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.637       |\n",
            "|    explained_variance   | 0.867        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 140          |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | -0.000881    |\n",
            "|    value_loss           | 399          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 229         |\n",
            "|    ep_rew_mean          | 264         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 907         |\n",
            "|    iterations           | 182         |\n",
            "|    time_elapsed         | 3284        |\n",
            "|    total_timesteps      | 2981888     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003374061 |\n",
            "|    clip_fraction        | 0.0338      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.606      |\n",
            "|    explained_variance   | 0.901       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 77          |\n",
            "|    n_updates            | 724         |\n",
            "|    policy_gradient_loss | -0.000597   |\n",
            "|    value_loss           | 331         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 246          |\n",
            "|    ep_rew_mean          | 268          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 909          |\n",
            "|    iterations           | 183          |\n",
            "|    time_elapsed         | 3296         |\n",
            "|    total_timesteps      | 2998272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042256345 |\n",
            "|    clip_fraction        | 0.0393       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.638       |\n",
            "|    explained_variance   | 0.945        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 38.2         |\n",
            "|    n_updates            | 728          |\n",
            "|    policy_gradient_loss | 0.000629     |\n",
            "|    value_loss           | 178          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3000000, episode_reward=271.87 +/- 13.21\n",
            "Episode length: 242.50 +/- 15.03\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 242          |\n",
            "|    mean_reward          | 272          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3000000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052812295 |\n",
            "|    clip_fraction        | 0.0566       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.63        |\n",
            "|    explained_variance   | 0.938        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 139          |\n",
            "|    n_updates            | 732          |\n",
            "|    policy_gradient_loss | 0.000612     |\n",
            "|    value_loss           | 190          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 241      |\n",
            "|    ep_rew_mean     | 270      |\n",
            "| time/              |          |\n",
            "|    fps             | 910      |\n",
            "|    iterations      | 184      |\n",
            "|    time_elapsed    | 3310     |\n",
            "|    total_timesteps | 3014656  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 244          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 912          |\n",
            "|    iterations           | 185          |\n",
            "|    time_elapsed         | 3323         |\n",
            "|    total_timesteps      | 3031040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033434602 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.634       |\n",
            "|    explained_variance   | 0.943        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 108          |\n",
            "|    n_updates            | 736          |\n",
            "|    policy_gradient_loss | 0.00067      |\n",
            "|    value_loss           | 137          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 241          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 913          |\n",
            "|    iterations           | 186          |\n",
            "|    time_elapsed         | 3336         |\n",
            "|    total_timesteps      | 3047424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044703037 |\n",
            "|    clip_fraction        | 0.0535       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.624       |\n",
            "|    explained_variance   | 0.99         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.69         |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | 0.000751     |\n",
            "|    value_loss           | 9.59         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 260          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 914          |\n",
            "|    iterations           | 187          |\n",
            "|    time_elapsed         | 3349         |\n",
            "|    total_timesteps      | 3063808      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037325681 |\n",
            "|    clip_fraction        | 0.0456       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.611       |\n",
            "|    explained_variance   | 0.953        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 27.3         |\n",
            "|    n_updates            | 744          |\n",
            "|    policy_gradient_loss | -0.000516    |\n",
            "|    value_loss           | 137          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 916          |\n",
            "|    iterations           | 188          |\n",
            "|    time_elapsed         | 3361         |\n",
            "|    total_timesteps      | 3080192      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036183973 |\n",
            "|    clip_fraction        | 0.045        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.609       |\n",
            "|    explained_variance   | 0.95         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.7         |\n",
            "|    n_updates            | 748          |\n",
            "|    policy_gradient_loss | -0.000339    |\n",
            "|    value_loss           | 141          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 242          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 917          |\n",
            "|    iterations           | 189          |\n",
            "|    time_elapsed         | 3374         |\n",
            "|    total_timesteps      | 3096576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025535135 |\n",
            "|    clip_fraction        | 0.0309       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0.952        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 242          |\n",
            "|    n_updates            | 752          |\n",
            "|    policy_gradient_loss | 0.00107      |\n",
            "|    value_loss           | 117          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3100000, episode_reward=267.34 +/- 20.95\n",
            "Episode length: 246.40 +/- 17.97\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 246          |\n",
            "|    mean_reward          | 267          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3100000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034220659 |\n",
            "|    clip_fraction        | 0.0335       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.621       |\n",
            "|    explained_variance   | 0.912        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 352          |\n",
            "|    n_updates            | 756          |\n",
            "|    policy_gradient_loss | 0.000444     |\n",
            "|    value_loss           | 287          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 246      |\n",
            "|    ep_rew_mean     | 268      |\n",
            "| time/              |          |\n",
            "|    fps             | 918      |\n",
            "|    iterations      | 190      |\n",
            "|    time_elapsed    | 3388     |\n",
            "|    total_timesteps | 3112960  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 231          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 920          |\n",
            "|    iterations           | 191          |\n",
            "|    time_elapsed         | 3401         |\n",
            "|    total_timesteps      | 3129344      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045984536 |\n",
            "|    clip_fraction        | 0.0538       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.607       |\n",
            "|    explained_variance   | 0.969        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 27.5         |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | 0.00046      |\n",
            "|    value_loss           | 84.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 252          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 921          |\n",
            "|    iterations           | 192          |\n",
            "|    time_elapsed         | 3413         |\n",
            "|    total_timesteps      | 3145728      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027463776 |\n",
            "|    clip_fraction        | 0.0279       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.607       |\n",
            "|    explained_variance   | 0.932        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 105          |\n",
            "|    n_updates            | 764          |\n",
            "|    policy_gradient_loss | -1.28e-05    |\n",
            "|    value_loss           | 200          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 238          |\n",
            "|    ep_rew_mean          | 259          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 922          |\n",
            "|    iterations           | 193          |\n",
            "|    time_elapsed         | 3426         |\n",
            "|    total_timesteps      | 3162112      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029076103 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.625       |\n",
            "|    explained_variance   | 0.881        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 115          |\n",
            "|    n_updates            | 768          |\n",
            "|    policy_gradient_loss | -0.000273    |\n",
            "|    value_loss           | 339          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 240          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 924          |\n",
            "|    iterations           | 194          |\n",
            "|    time_elapsed         | 3439         |\n",
            "|    total_timesteps      | 3178496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030114353 |\n",
            "|    clip_fraction        | 0.0379       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.592       |\n",
            "|    explained_variance   | 0.923        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 220          |\n",
            "|    n_updates            | 772          |\n",
            "|    policy_gradient_loss | 0.000461     |\n",
            "|    value_loss           | 210          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 234          |\n",
            "|    ep_rew_mean          | 253          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 925          |\n",
            "|    iterations           | 195          |\n",
            "|    time_elapsed         | 3452         |\n",
            "|    total_timesteps      | 3194880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031719091 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.598       |\n",
            "|    explained_variance   | 0.953        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 39.4         |\n",
            "|    n_updates            | 776          |\n",
            "|    policy_gradient_loss | -0.000186    |\n",
            "|    value_loss           | 93           |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3200000, episode_reward=285.83 +/- 15.34\n",
            "Episode length: 234.00 +/- 9.11\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 234          |\n",
            "|    mean_reward          | 286          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3200000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033866256 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.603       |\n",
            "|    explained_variance   | 0.857        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 214          |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.000727    |\n",
            "|    value_loss           | 461          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 236      |\n",
            "|    ep_rew_mean     | 259      |\n",
            "| time/              |          |\n",
            "|    fps             | 926      |\n",
            "|    iterations      | 196      |\n",
            "|    time_elapsed    | 3465     |\n",
            "|    total_timesteps | 3211264  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 238          |\n",
            "|    ep_rew_mean          | 256          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 928          |\n",
            "|    iterations           | 197          |\n",
            "|    time_elapsed         | 3477         |\n",
            "|    total_timesteps      | 3227648      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029293261 |\n",
            "|    clip_fraction        | 0.0471       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.601       |\n",
            "|    explained_variance   | 0.925        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.8         |\n",
            "|    n_updates            | 784          |\n",
            "|    policy_gradient_loss | 0.00103      |\n",
            "|    value_loss           | 184          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 243          |\n",
            "|    ep_rew_mean          | 262          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 929          |\n",
            "|    iterations           | 198          |\n",
            "|    time_elapsed         | 3490         |\n",
            "|    total_timesteps      | 3244032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029562195 |\n",
            "|    clip_fraction        | 0.0377       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.62        |\n",
            "|    explained_variance   | 0.907        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 390          |\n",
            "|    n_updates            | 788          |\n",
            "|    policy_gradient_loss | 9.06e-05     |\n",
            "|    value_loss           | 280          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 255          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 930          |\n",
            "|    iterations           | 199          |\n",
            "|    time_elapsed         | 3503         |\n",
            "|    total_timesteps      | 3260416      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040259175 |\n",
            "|    clip_fraction        | 0.0425       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.608       |\n",
            "|    explained_variance   | 0.922        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 11.5         |\n",
            "|    n_updates            | 792          |\n",
            "|    policy_gradient_loss | 0.000447     |\n",
            "|    value_loss           | 215          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 266         |\n",
            "|    ep_rew_mean          | 270         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 931         |\n",
            "|    iterations           | 200         |\n",
            "|    time_elapsed         | 3516        |\n",
            "|    total_timesteps      | 3276800     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008104546 |\n",
            "|    clip_fraction        | 0.0719      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.611      |\n",
            "|    explained_variance   | 0.959       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 114         |\n",
            "|    n_updates            | 796         |\n",
            "|    policy_gradient_loss | 0.000946    |\n",
            "|    value_loss           | 112         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 257          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 933          |\n",
            "|    iterations           | 201          |\n",
            "|    time_elapsed         | 3529         |\n",
            "|    total_timesteps      | 3293184      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038533742 |\n",
            "|    clip_fraction        | 0.0345       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.596       |\n",
            "|    explained_variance   | 0.941        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.15         |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | 0.000736     |\n",
            "|    value_loss           | 155          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3300000, episode_reward=271.89 +/- 12.55\n",
            "Episode length: 233.50 +/- 11.36\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 234          |\n",
            "|    mean_reward          | 272          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3300000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047328947 |\n",
            "|    clip_fraction        | 0.0523       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.609       |\n",
            "|    explained_variance   | 0.951        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 148          |\n",
            "|    n_updates            | 804          |\n",
            "|    policy_gradient_loss | 0.00045      |\n",
            "|    value_loss           | 136          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 256      |\n",
            "|    ep_rew_mean     | 274      |\n",
            "| time/              |          |\n",
            "|    fps             | 934      |\n",
            "|    iterations      | 202      |\n",
            "|    time_elapsed    | 3543     |\n",
            "|    total_timesteps | 3309568  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 249         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 935         |\n",
            "|    iterations           | 203         |\n",
            "|    time_elapsed         | 3556        |\n",
            "|    total_timesteps      | 3325952     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003917422 |\n",
            "|    clip_fraction        | 0.0443      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.604      |\n",
            "|    explained_variance   | 0.972       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 91.9        |\n",
            "|    n_updates            | 808         |\n",
            "|    policy_gradient_loss | 0.00103     |\n",
            "|    value_loss           | 71.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 261         |\n",
            "|    ep_rew_mean          | 270         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 935         |\n",
            "|    iterations           | 204         |\n",
            "|    time_elapsed         | 3571        |\n",
            "|    total_timesteps      | 3342336     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004046301 |\n",
            "|    clip_fraction        | 0.0493      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.619      |\n",
            "|    explained_variance   | 0.967       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.69        |\n",
            "|    n_updates            | 812         |\n",
            "|    policy_gradient_loss | 0.000691    |\n",
            "|    value_loss           | 95.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 271          |\n",
            "|    ep_rew_mean          | 260          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 936          |\n",
            "|    iterations           | 205          |\n",
            "|    time_elapsed         | 3584         |\n",
            "|    total_timesteps      | 3358720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061792377 |\n",
            "|    clip_fraction        | 0.0632       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.647       |\n",
            "|    explained_variance   | 0.966        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 228          |\n",
            "|    n_updates            | 816          |\n",
            "|    policy_gradient_loss | 0.000299     |\n",
            "|    value_loss           | 86.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 253          |\n",
            "|    ep_rew_mean          | 260          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 937          |\n",
            "|    iterations           | 206          |\n",
            "|    time_elapsed         | 3598         |\n",
            "|    total_timesteps      | 3375104      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028868602 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.627       |\n",
            "|    explained_variance   | 0.894        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 118          |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.000978    |\n",
            "|    value_loss           | 271          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 279          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 938          |\n",
            "|    iterations           | 207          |\n",
            "|    time_elapsed         | 3612         |\n",
            "|    total_timesteps      | 3391488      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038714746 |\n",
            "|    clip_fraction        | 0.0301       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.625       |\n",
            "|    explained_variance   | 0.93         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 113          |\n",
            "|    n_updates            | 824          |\n",
            "|    policy_gradient_loss | -0.000325    |\n",
            "|    value_loss           | 216          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3400000, episode_reward=277.22 +/- 24.16\n",
            "Episode length: 232.70 +/- 17.77\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 233         |\n",
            "|    mean_reward          | 277         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3400000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003394405 |\n",
            "|    clip_fraction        | 0.0504      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.632      |\n",
            "|    explained_variance   | 0.973       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 23.8        |\n",
            "|    n_updates            | 828         |\n",
            "|    policy_gradient_loss | 0.000836    |\n",
            "|    value_loss           | 67.9        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 289      |\n",
            "|    ep_rew_mean     | 262      |\n",
            "| time/              |          |\n",
            "|    fps             | 939      |\n",
            "|    iterations      | 208      |\n",
            "|    time_elapsed    | 3628     |\n",
            "|    total_timesteps | 3407872  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 282         |\n",
            "|    ep_rew_mean          | 261         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 940         |\n",
            "|    iterations           | 209         |\n",
            "|    time_elapsed         | 3641        |\n",
            "|    total_timesteps      | 3424256     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002791091 |\n",
            "|    clip_fraction        | 0.0294      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.621      |\n",
            "|    explained_variance   | 0.918       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 237         |\n",
            "|    n_updates            | 832         |\n",
            "|    policy_gradient_loss | -0.000776   |\n",
            "|    value_loss           | 259         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 266         |\n",
            "|    ep_rew_mean          | 269         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 941         |\n",
            "|    iterations           | 210         |\n",
            "|    time_elapsed         | 3654        |\n",
            "|    total_timesteps      | 3440640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004715494 |\n",
            "|    clip_fraction        | 0.0432      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.626      |\n",
            "|    explained_variance   | 0.945       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 90.2        |\n",
            "|    n_updates            | 836         |\n",
            "|    policy_gradient_loss | 0.000323    |\n",
            "|    value_loss           | 187         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 270          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 942          |\n",
            "|    iterations           | 211          |\n",
            "|    time_elapsed         | 3668         |\n",
            "|    total_timesteps      | 3457024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041504726 |\n",
            "|    clip_fraction        | 0.0554       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0.991        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.75         |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | 0.000685     |\n",
            "|    value_loss           | 12.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 269          |\n",
            "|    ep_rew_mean          | 264          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 943          |\n",
            "|    iterations           | 212          |\n",
            "|    time_elapsed         | 3681         |\n",
            "|    total_timesteps      | 3473408      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022407428 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | 0.956        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 159          |\n",
            "|    n_updates            | 844          |\n",
            "|    policy_gradient_loss | 0.000402     |\n",
            "|    value_loss           | 125          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 275          |\n",
            "|    ep_rew_mean          | 260          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 944          |\n",
            "|    iterations           | 213          |\n",
            "|    time_elapsed         | 3696         |\n",
            "|    total_timesteps      | 3489792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046267784 |\n",
            "|    clip_fraction        | 0.0455       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.643       |\n",
            "|    explained_variance   | 0.975        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 157          |\n",
            "|    n_updates            | 848          |\n",
            "|    policy_gradient_loss | 0.000345     |\n",
            "|    value_loss           | 74.7         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3500000, episode_reward=275.39 +/- 10.53\n",
            "Episode length: 236.40 +/- 11.16\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 236         |\n",
            "|    mean_reward          | 275         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3500000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003788991 |\n",
            "|    clip_fraction        | 0.0399      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.637      |\n",
            "|    explained_variance   | 0.933       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.71        |\n",
            "|    n_updates            | 852         |\n",
            "|    policy_gradient_loss | -0.00038    |\n",
            "|    value_loss           | 153         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 283      |\n",
            "|    ep_rew_mean     | 268      |\n",
            "| time/              |          |\n",
            "|    fps             | 944      |\n",
            "|    iterations      | 214      |\n",
            "|    time_elapsed    | 3710     |\n",
            "|    total_timesteps | 3506176  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 254          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 946          |\n",
            "|    iterations           | 215          |\n",
            "|    time_elapsed         | 3723         |\n",
            "|    total_timesteps      | 3522560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044053392 |\n",
            "|    clip_fraction        | 0.0484       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.614       |\n",
            "|    explained_variance   | 0.972        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.58         |\n",
            "|    n_updates            | 856          |\n",
            "|    policy_gradient_loss | -9.35e-05    |\n",
            "|    value_loss           | 97.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 245          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 946          |\n",
            "|    iterations           | 216          |\n",
            "|    time_elapsed         | 3737         |\n",
            "|    total_timesteps      | 3538944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042239306 |\n",
            "|    clip_fraction        | 0.0531       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.636       |\n",
            "|    explained_variance   | 0.978        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.53         |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | 0.000753     |\n",
            "|    value_loss           | 68.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 260          |\n",
            "|    ep_rew_mean          | 258          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 947          |\n",
            "|    iterations           | 217          |\n",
            "|    time_elapsed         | 3751         |\n",
            "|    total_timesteps      | 3555328      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035634001 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0.944        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.28         |\n",
            "|    n_updates            | 864          |\n",
            "|    policy_gradient_loss | -0.000153    |\n",
            "|    value_loss           | 175          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 253          |\n",
            "|    ep_rew_mean          | 262          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 948          |\n",
            "|    iterations           | 218          |\n",
            "|    time_elapsed         | 3764         |\n",
            "|    total_timesteps      | 3571712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025448161 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.604       |\n",
            "|    explained_variance   | 0.927        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.5         |\n",
            "|    n_updates            | 868          |\n",
            "|    policy_gradient_loss | 8.09e-05     |\n",
            "|    value_loss           | 223          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 246          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 949          |\n",
            "|    iterations           | 219          |\n",
            "|    time_elapsed         | 3777         |\n",
            "|    total_timesteps      | 3588096      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046964157 |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.637       |\n",
            "|    explained_variance   | 0.948        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12.3         |\n",
            "|    n_updates            | 872          |\n",
            "|    policy_gradient_loss | 0.00106      |\n",
            "|    value_loss           | 158          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3600000, episode_reward=275.59 +/- 16.59\n",
            "Episode length: 239.60 +/- 15.01\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 240          |\n",
            "|    mean_reward          | 276          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3600000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048109246 |\n",
            "|    clip_fraction        | 0.0473       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.613       |\n",
            "|    explained_variance   | 0.969        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.66         |\n",
            "|    n_updates            | 876          |\n",
            "|    policy_gradient_loss | 0.00069      |\n",
            "|    value_loss           | 73.6         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 235      |\n",
            "|    ep_rew_mean     | 272      |\n",
            "| time/              |          |\n",
            "|    fps             | 950      |\n",
            "|    iterations      | 220      |\n",
            "|    time_elapsed    | 3791     |\n",
            "|    total_timesteps | 3604480  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 235          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 951          |\n",
            "|    iterations           | 221          |\n",
            "|    time_elapsed         | 3804         |\n",
            "|    total_timesteps      | 3620864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037208018 |\n",
            "|    clip_fraction        | 0.03         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.587       |\n",
            "|    explained_variance   | 0.932        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 11.1         |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.000482    |\n",
            "|    value_loss           | 202          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 246         |\n",
            "|    ep_rew_mean          | 274         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 952         |\n",
            "|    iterations           | 222         |\n",
            "|    time_elapsed         | 3816        |\n",
            "|    total_timesteps      | 3637248     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003155427 |\n",
            "|    clip_fraction        | 0.0516      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.614      |\n",
            "|    explained_variance   | 0.971       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.4        |\n",
            "|    n_updates            | 884         |\n",
            "|    policy_gradient_loss | 0.00172     |\n",
            "|    value_loss           | 74.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 249         |\n",
            "|    ep_rew_mean          | 265         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 953         |\n",
            "|    iterations           | 223         |\n",
            "|    time_elapsed         | 3830        |\n",
            "|    total_timesteps      | 3653632     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003985323 |\n",
            "|    clip_fraction        | 0.044       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.621      |\n",
            "|    explained_variance   | 0.992       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 11.2        |\n",
            "|    n_updates            | 888         |\n",
            "|    policy_gradient_loss | 0.00099     |\n",
            "|    value_loss           | 19.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 248          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 954          |\n",
            "|    iterations           | 224          |\n",
            "|    time_elapsed         | 3843         |\n",
            "|    total_timesteps      | 3670016      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033312433 |\n",
            "|    clip_fraction        | 0.0345       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.591       |\n",
            "|    explained_variance   | 0.933        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 91.4         |\n",
            "|    n_updates            | 892          |\n",
            "|    policy_gradient_loss | -0.000106    |\n",
            "|    value_loss           | 151          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 241          |\n",
            "|    ep_rew_mean          | 262          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 956          |\n",
            "|    iterations           | 225          |\n",
            "|    time_elapsed         | 3855         |\n",
            "|    total_timesteps      | 3686400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034570629 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.594       |\n",
            "|    explained_variance   | 0.945        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.97         |\n",
            "|    n_updates            | 896          |\n",
            "|    policy_gradient_loss | 0.000283     |\n",
            "|    value_loss           | 153          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3700000, episode_reward=282.16 +/- 24.29\n",
            "Episode length: 232.00 +/- 16.53\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 232         |\n",
            "|    mean_reward          | 282         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3700000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002622847 |\n",
            "|    clip_fraction        | 0.0246      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.556      |\n",
            "|    explained_variance   | 0.909       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 93.9        |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | 0.000137    |\n",
            "|    value_loss           | 268         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 237      |\n",
            "|    ep_rew_mean     | 261      |\n",
            "| time/              |          |\n",
            "|    fps             | 956      |\n",
            "|    iterations      | 226      |\n",
            "|    time_elapsed    | 3870     |\n",
            "|    total_timesteps | 3702784  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 243          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 957          |\n",
            "|    iterations           | 227          |\n",
            "|    time_elapsed         | 3883         |\n",
            "|    total_timesteps      | 3719168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046017533 |\n",
            "|    clip_fraction        | 0.0445       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.582       |\n",
            "|    explained_variance   | 0.957        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 53.1         |\n",
            "|    n_updates            | 904          |\n",
            "|    policy_gradient_loss | 0.000656     |\n",
            "|    value_loss           | 141          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 235          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 958          |\n",
            "|    iterations           | 228          |\n",
            "|    time_elapsed         | 3895         |\n",
            "|    total_timesteps      | 3735552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037770066 |\n",
            "|    clip_fraction        | 0.0416       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.571       |\n",
            "|    explained_variance   | 0.946        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 40.8         |\n",
            "|    n_updates            | 908          |\n",
            "|    policy_gradient_loss | 0.00072      |\n",
            "|    value_loss           | 116          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 224          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 959          |\n",
            "|    iterations           | 229          |\n",
            "|    time_elapsed         | 3908         |\n",
            "|    total_timesteps      | 3751936      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034665377 |\n",
            "|    clip_fraction        | 0.0495       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.594       |\n",
            "|    explained_variance   | 0.945        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 60.1         |\n",
            "|    n_updates            | 912          |\n",
            "|    policy_gradient_loss | 0.000377     |\n",
            "|    value_loss           | 140          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 220          |\n",
            "|    ep_rew_mean          | 260          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 230          |\n",
            "|    time_elapsed         | 3920         |\n",
            "|    total_timesteps      | 3768320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046320637 |\n",
            "|    clip_fraction        | 0.0446       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.572       |\n",
            "|    explained_variance   | 0.928        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 75.2         |\n",
            "|    n_updates            | 916          |\n",
            "|    policy_gradient_loss | -0.000414    |\n",
            "|    value_loss           | 210          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 236          |\n",
            "|    ep_rew_mean          | 247          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 962          |\n",
            "|    iterations           | 231          |\n",
            "|    time_elapsed         | 3933         |\n",
            "|    total_timesteps      | 3784704      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029853801 |\n",
            "|    clip_fraction        | 0.022        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.584       |\n",
            "|    explained_variance   | 0.894        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 63.7         |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -6.55e-05    |\n",
            "|    value_loss           | 309          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3800000, episode_reward=287.42 +/- 21.34\n",
            "Episode length: 222.10 +/- 11.50\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 222         |\n",
            "|    mean_reward          | 287         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3800000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003246516 |\n",
            "|    clip_fraction        | 0.0297      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.591      |\n",
            "|    explained_variance   | 0.919       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 112         |\n",
            "|    n_updates            | 924         |\n",
            "|    policy_gradient_loss | 0.000329    |\n",
            "|    value_loss           | 358         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 235      |\n",
            "|    ep_rew_mean     | 265      |\n",
            "| time/              |          |\n",
            "|    fps             | 963      |\n",
            "|    iterations      | 232      |\n",
            "|    time_elapsed    | 3947     |\n",
            "|    total_timesteps | 3801088  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 258          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 963          |\n",
            "|    iterations           | 233          |\n",
            "|    time_elapsed         | 3960         |\n",
            "|    total_timesteps      | 3817472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049484465 |\n",
            "|    clip_fraction        | 0.0511       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.577       |\n",
            "|    explained_variance   | 0.907        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 41.1         |\n",
            "|    n_updates            | 928          |\n",
            "|    policy_gradient_loss | 0.000216     |\n",
            "|    value_loss           | 248          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 232          |\n",
            "|    ep_rew_mean          | 256          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 964          |\n",
            "|    iterations           | 234          |\n",
            "|    time_elapsed         | 3973         |\n",
            "|    total_timesteps      | 3833856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033548083 |\n",
            "|    clip_fraction        | 0.0418       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.595       |\n",
            "|    explained_variance   | 0.914        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 145          |\n",
            "|    n_updates            | 932          |\n",
            "|    policy_gradient_loss | 0.000356     |\n",
            "|    value_loss           | 293          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 240          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 965          |\n",
            "|    iterations           | 235          |\n",
            "|    time_elapsed         | 3986         |\n",
            "|    total_timesteps      | 3850240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039539197 |\n",
            "|    clip_fraction        | 0.0509       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.587       |\n",
            "|    explained_variance   | 0.954        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.5         |\n",
            "|    n_updates            | 936          |\n",
            "|    policy_gradient_loss | 0.000619     |\n",
            "|    value_loss           | 120          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 249          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 966          |\n",
            "|    iterations           | 236          |\n",
            "|    time_elapsed         | 4000         |\n",
            "|    total_timesteps      | 3866624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050345496 |\n",
            "|    clip_fraction        | 0.0435       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.576       |\n",
            "|    explained_variance   | 0.905        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 277          |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | 0.000145     |\n",
            "|    value_loss           | 278          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 967          |\n",
            "|    iterations           | 237          |\n",
            "|    time_elapsed         | 4012         |\n",
            "|    total_timesteps      | 3883008      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041601807 |\n",
            "|    clip_fraction        | 0.0571       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.575       |\n",
            "|    explained_variance   | 0.97         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 70           |\n",
            "|    n_updates            | 944          |\n",
            "|    policy_gradient_loss | 0.0014       |\n",
            "|    value_loss           | 41.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 242         |\n",
            "|    ep_rew_mean          | 264         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 968         |\n",
            "|    iterations           | 238         |\n",
            "|    time_elapsed         | 4026        |\n",
            "|    total_timesteps      | 3899392     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004722567 |\n",
            "|    clip_fraction        | 0.0504      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.589      |\n",
            "|    explained_variance   | 0.983       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 77.4        |\n",
            "|    n_updates            | 948         |\n",
            "|    policy_gradient_loss | 0.000817    |\n",
            "|    value_loss           | 34.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=3900000, episode_reward=281.09 +/- 15.38\n",
            "Episode length: 231.20 +/- 19.37\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 231          |\n",
            "|    mean_reward          | 281          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3900000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035514396 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0.951        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.06         |\n",
            "|    n_updates            | 952          |\n",
            "|    policy_gradient_loss | -0.000707    |\n",
            "|    value_loss           | 126          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 259      |\n",
            "|    ep_rew_mean     | 261      |\n",
            "| time/              |          |\n",
            "|    fps             | 968      |\n",
            "|    iterations      | 239      |\n",
            "|    time_elapsed    | 4041     |\n",
            "|    total_timesteps | 3915776  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 254         |\n",
            "|    ep_rew_mean          | 263         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 969         |\n",
            "|    iterations           | 240         |\n",
            "|    time_elapsed         | 4055        |\n",
            "|    total_timesteps      | 3932160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002977808 |\n",
            "|    clip_fraction        | 0.0253      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.609      |\n",
            "|    explained_variance   | 0.919       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 40.6        |\n",
            "|    n_updates            | 956         |\n",
            "|    policy_gradient_loss | -9.08e-05   |\n",
            "|    value_loss           | 232         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 259          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 970          |\n",
            "|    iterations           | 241          |\n",
            "|    time_elapsed         | 4070         |\n",
            "|    total_timesteps      | 3948544      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056487024 |\n",
            "|    clip_fraction        | 0.0644       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.6         |\n",
            "|    explained_variance   | 0.968        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 282          |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | 5.18e-05     |\n",
            "|    value_loss           | 102          |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 268        |\n",
            "|    ep_rew_mean          | 274        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 970        |\n",
            "|    iterations           | 242        |\n",
            "|    time_elapsed         | 4084       |\n",
            "|    total_timesteps      | 3964928    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00509526 |\n",
            "|    clip_fraction        | 0.0471     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.6       |\n",
            "|    explained_variance   | 0.97       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.61       |\n",
            "|    n_updates            | 964        |\n",
            "|    policy_gradient_loss | 0.000784   |\n",
            "|    value_loss           | 103        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 260         |\n",
            "|    ep_rew_mean          | 270         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 971         |\n",
            "|    iterations           | 243         |\n",
            "|    time_elapsed         | 4098        |\n",
            "|    total_timesteps      | 3981312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005025921 |\n",
            "|    clip_fraction        | 0.0554      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.608      |\n",
            "|    explained_variance   | 0.982       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.24        |\n",
            "|    n_updates            | 968         |\n",
            "|    policy_gradient_loss | 0.00111     |\n",
            "|    value_loss           | 42.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 261          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 972          |\n",
            "|    iterations           | 244          |\n",
            "|    time_elapsed         | 4111         |\n",
            "|    total_timesteps      | 3997696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037454716 |\n",
            "|    clip_fraction        | 0.0496       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.609       |\n",
            "|    explained_variance   | 0.979        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.17         |\n",
            "|    n_updates            | 972          |\n",
            "|    policy_gradient_loss | 0.00053      |\n",
            "|    value_loss           | 67.5         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4000000, episode_reward=278.66 +/- 16.12\n",
            "Episode length: 229.60 +/- 15.38\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 230          |\n",
            "|    mean_reward          | 279          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4000000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022650906 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.59        |\n",
            "|    explained_variance   | 0.922        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 19           |\n",
            "|    n_updates            | 976          |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    value_loss           | 203          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 231      |\n",
            "|    ep_rew_mean     | 276      |\n",
            "| time/              |          |\n",
            "|    fps             | 972      |\n",
            "|    iterations      | 245      |\n",
            "|    time_elapsed    | 4126     |\n",
            "|    total_timesteps | 4014080  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 237         |\n",
            "|    ep_rew_mean          | 273         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 973         |\n",
            "|    iterations           | 246         |\n",
            "|    time_elapsed         | 4139        |\n",
            "|    total_timesteps      | 4030464     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004928364 |\n",
            "|    clip_fraction        | 0.0407      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.559      |\n",
            "|    explained_variance   | 0.95        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.17        |\n",
            "|    n_updates            | 980         |\n",
            "|    policy_gradient_loss | -0.000127   |\n",
            "|    value_loss           | 150         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 243          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 974          |\n",
            "|    iterations           | 247          |\n",
            "|    time_elapsed         | 4153         |\n",
            "|    total_timesteps      | 4046848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044848113 |\n",
            "|    clip_fraction        | 0.0387       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.586       |\n",
            "|    explained_variance   | 0.963        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.6         |\n",
            "|    n_updates            | 984          |\n",
            "|    policy_gradient_loss | 0.000151     |\n",
            "|    value_loss           | 74.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 239         |\n",
            "|    ep_rew_mean          | 270         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 974         |\n",
            "|    iterations           | 248         |\n",
            "|    time_elapsed         | 4167        |\n",
            "|    total_timesteps      | 4063232     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004447895 |\n",
            "|    clip_fraction        | 0.0402      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.573      |\n",
            "|    explained_variance   | 0.959       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 153         |\n",
            "|    n_updates            | 988         |\n",
            "|    policy_gradient_loss | 0.0012      |\n",
            "|    value_loss           | 111         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 241          |\n",
            "|    ep_rew_mean          | 266          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 975          |\n",
            "|    iterations           | 249          |\n",
            "|    time_elapsed         | 4181         |\n",
            "|    total_timesteps      | 4079616      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038168742 |\n",
            "|    clip_fraction        | 0.0302       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.591       |\n",
            "|    explained_variance   | 0.907        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.4         |\n",
            "|    n_updates            | 992          |\n",
            "|    policy_gradient_loss | 1.53e-05     |\n",
            "|    value_loss           | 239          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 242          |\n",
            "|    ep_rew_mean          | 268          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 976          |\n",
            "|    iterations           | 250          |\n",
            "|    time_elapsed         | 4194         |\n",
            "|    total_timesteps      | 4096000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035803395 |\n",
            "|    clip_fraction        | 0.0378       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.595       |\n",
            "|    explained_variance   | 0.95         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 143          |\n",
            "|    n_updates            | 996          |\n",
            "|    policy_gradient_loss | 0.00125      |\n",
            "|    value_loss           | 125          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4100000, episode_reward=285.35 +/- 16.22\n",
            "Episode length: 241.80 +/- 17.52\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 242          |\n",
            "|    mean_reward          | 285          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4100000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049272743 |\n",
            "|    clip_fraction        | 0.0603       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.614       |\n",
            "|    explained_variance   | 0.966        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.17         |\n",
            "|    n_updates            | 1000         |\n",
            "|    policy_gradient_loss | 0.000374     |\n",
            "|    value_loss           | 96.6         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 244      |\n",
            "|    ep_rew_mean     | 267      |\n",
            "| time/              |          |\n",
            "|    fps             | 977      |\n",
            "|    iterations      | 251      |\n",
            "|    time_elapsed    | 4208     |\n",
            "|    total_timesteps | 4112384  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 234         |\n",
            "|    ep_rew_mean          | 279         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 978         |\n",
            "|    iterations           | 252         |\n",
            "|    time_elapsed         | 4220        |\n",
            "|    total_timesteps      | 4128768     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003287349 |\n",
            "|    clip_fraction        | 0.0385      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.615      |\n",
            "|    explained_variance   | 0.963       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.7         |\n",
            "|    n_updates            | 1004        |\n",
            "|    policy_gradient_loss | 0.000563    |\n",
            "|    value_loss           | 88.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 230          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 979          |\n",
            "|    iterations           | 253          |\n",
            "|    time_elapsed         | 4233         |\n",
            "|    total_timesteps      | 4145152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052353516 |\n",
            "|    clip_fraction        | 0.0466       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.584       |\n",
            "|    explained_variance   | 0.986        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 28.2         |\n",
            "|    n_updates            | 1008         |\n",
            "|    policy_gradient_loss | 0.00176      |\n",
            "|    value_loss           | 24.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 228          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 980          |\n",
            "|    iterations           | 254          |\n",
            "|    time_elapsed         | 4245         |\n",
            "|    total_timesteps      | 4161536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023231858 |\n",
            "|    clip_fraction        | 0.0176       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.588       |\n",
            "|    explained_variance   | 0.93         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.52         |\n",
            "|    n_updates            | 1012         |\n",
            "|    policy_gradient_loss | -0.000803    |\n",
            "|    value_loss           | 199          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 238          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 981          |\n",
            "|    iterations           | 255          |\n",
            "|    time_elapsed         | 4258         |\n",
            "|    total_timesteps      | 4177920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037258388 |\n",
            "|    clip_fraction        | 0.0471       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.604       |\n",
            "|    explained_variance   | 0.971        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 32.3         |\n",
            "|    n_updates            | 1016         |\n",
            "|    policy_gradient_loss | 0.00111      |\n",
            "|    value_loss           | 70.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 248          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 981          |\n",
            "|    iterations           | 256          |\n",
            "|    time_elapsed         | 4272         |\n",
            "|    total_timesteps      | 4194304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043672263 |\n",
            "|    clip_fraction        | 0.0598       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.597       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.84         |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | 0.00207      |\n",
            "|    value_loss           | 4.33         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4200000, episode_reward=278.33 +/- 18.83\n",
            "Episode length: 236.70 +/- 16.35\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 237         |\n",
            "|    mean_reward          | 278         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 4200000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003089339 |\n",
            "|    clip_fraction        | 0.0344      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.614      |\n",
            "|    explained_variance   | 0.948       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.79        |\n",
            "|    n_updates            | 1024        |\n",
            "|    policy_gradient_loss | 0.000326    |\n",
            "|    value_loss           | 153         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 251      |\n",
            "|    ep_rew_mean     | 274      |\n",
            "| time/              |          |\n",
            "|    fps             | 982      |\n",
            "|    iterations      | 257      |\n",
            "|    time_elapsed    | 4287     |\n",
            "|    total_timesteps | 4210688  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 237          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 258          |\n",
            "|    time_elapsed         | 4299         |\n",
            "|    total_timesteps      | 4227072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034352592 |\n",
            "|    clip_fraction        | 0.0475       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.61        |\n",
            "|    explained_variance   | 0.993        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.78         |\n",
            "|    n_updates            | 1028         |\n",
            "|    policy_gradient_loss | 0.000861     |\n",
            "|    value_loss           | 6.57         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 232          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 259          |\n",
            "|    time_elapsed         | 4311         |\n",
            "|    total_timesteps      | 4243456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030785003 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.584       |\n",
            "|    explained_variance   | 0.965        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 17           |\n",
            "|    n_updates            | 1032         |\n",
            "|    policy_gradient_loss | 0.000161     |\n",
            "|    value_loss           | 94           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 232         |\n",
            "|    ep_rew_mean          | 275         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 985         |\n",
            "|    iterations           | 260         |\n",
            "|    time_elapsed         | 4324        |\n",
            "|    total_timesteps      | 4259840     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004168531 |\n",
            "|    clip_fraction        | 0.0347      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.577      |\n",
            "|    explained_variance   | 0.96        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.46        |\n",
            "|    n_updates            | 1036        |\n",
            "|    policy_gradient_loss | -1.88e-05   |\n",
            "|    value_loss           | 114         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 261          |\n",
            "|    time_elapsed         | 4338         |\n",
            "|    total_timesteps      | 4276224      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037236472 |\n",
            "|    clip_fraction        | 0.0292       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.573       |\n",
            "|    explained_variance   | 0.948        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 294          |\n",
            "|    n_updates            | 1040         |\n",
            "|    policy_gradient_loss | 0.000287     |\n",
            "|    value_loss           | 161          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 237          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 262          |\n",
            "|    time_elapsed         | 4350         |\n",
            "|    total_timesteps      | 4292608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037296352 |\n",
            "|    clip_fraction        | 0.0504       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.6         |\n",
            "|    explained_variance   | 0.975        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.76         |\n",
            "|    n_updates            | 1044         |\n",
            "|    policy_gradient_loss | 0.000964     |\n",
            "|    value_loss           | 43.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4300000, episode_reward=284.08 +/- 20.86\n",
            "Episode length: 228.10 +/- 12.76\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 228          |\n",
            "|    mean_reward          | 284          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4300000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038242554 |\n",
            "|    clip_fraction        | 0.0495       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.594       |\n",
            "|    explained_variance   | 0.959        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.21         |\n",
            "|    n_updates            | 1048         |\n",
            "|    policy_gradient_loss | -0.00012     |\n",
            "|    value_loss           | 83.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 231      |\n",
            "|    ep_rew_mean     | 276      |\n",
            "| time/              |          |\n",
            "|    fps             | 987      |\n",
            "|    iterations      | 263      |\n",
            "|    time_elapsed    | 4365     |\n",
            "|    total_timesteps | 4308992  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 229         |\n",
            "|    ep_rew_mean          | 277         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 988         |\n",
            "|    iterations           | 264         |\n",
            "|    time_elapsed         | 4377        |\n",
            "|    total_timesteps      | 4325376     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005016034 |\n",
            "|    clip_fraction        | 0.0517      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.567      |\n",
            "|    explained_variance   | 0.964       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.2         |\n",
            "|    n_updates            | 1052        |\n",
            "|    policy_gradient_loss | 0.000738    |\n",
            "|    value_loss           | 87.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 231          |\n",
            "|    ep_rew_mean          | 273          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 988          |\n",
            "|    iterations           | 265          |\n",
            "|    time_elapsed         | 4390         |\n",
            "|    total_timesteps      | 4341760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035639987 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.555       |\n",
            "|    explained_variance   | 0.964        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 27.4         |\n",
            "|    n_updates            | 1056         |\n",
            "|    policy_gradient_loss | 8.42e-05     |\n",
            "|    value_loss           | 102          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 233         |\n",
            "|    ep_rew_mean          | 279         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 989         |\n",
            "|    iterations           | 266         |\n",
            "|    time_elapsed         | 4403        |\n",
            "|    total_timesteps      | 4358144     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004136771 |\n",
            "|    clip_fraction        | 0.046       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.572      |\n",
            "|    explained_variance   | 0.955       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 95.1        |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | 0.00039     |\n",
            "|    value_loss           | 136         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 246         |\n",
            "|    ep_rew_mean          | 271         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 990         |\n",
            "|    iterations           | 267         |\n",
            "|    time_elapsed         | 4418        |\n",
            "|    total_timesteps      | 4374528     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004844058 |\n",
            "|    clip_fraction        | 0.0658      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.543      |\n",
            "|    explained_variance   | 0.967       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 175         |\n",
            "|    n_updates            | 1064        |\n",
            "|    policy_gradient_loss | 0.00036     |\n",
            "|    value_loss           | 90.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 269         |\n",
            "|    ep_rew_mean          | 267         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 990         |\n",
            "|    iterations           | 268         |\n",
            "|    time_elapsed         | 4431        |\n",
            "|    total_timesteps      | 4390912     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004548425 |\n",
            "|    clip_fraction        | 0.0546      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.583      |\n",
            "|    explained_variance   | 0.964       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.76        |\n",
            "|    n_updates            | 1068        |\n",
            "|    policy_gradient_loss | 0.000793    |\n",
            "|    value_loss           | 117         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=4400000, episode_reward=276.52 +/- 23.85\n",
            "Episode length: 238.00 +/- 18.09\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 238          |\n",
            "|    mean_reward          | 277          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4400000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036918097 |\n",
            "|    clip_fraction        | 0.0345       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.555       |\n",
            "|    explained_variance   | 0.978        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12.6         |\n",
            "|    n_updates            | 1072         |\n",
            "|    policy_gradient_loss | 0.000685     |\n",
            "|    value_loss           | 40.6         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 238      |\n",
            "|    ep_rew_mean     | 275      |\n",
            "| time/              |          |\n",
            "|    fps             | 991      |\n",
            "|    iterations      | 269      |\n",
            "|    time_elapsed    | 4445     |\n",
            "|    total_timesteps | 4407296  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 240          |\n",
            "|    ep_rew_mean          | 280          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 991          |\n",
            "|    iterations           | 270          |\n",
            "|    time_elapsed         | 4459         |\n",
            "|    total_timesteps      | 4423680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037197452 |\n",
            "|    clip_fraction        | 0.0344       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.556       |\n",
            "|    explained_variance   | 0.942        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 23.2         |\n",
            "|    n_updates            | 1076         |\n",
            "|    policy_gradient_loss | 0.000337     |\n",
            "|    value_loss           | 179          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 248         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 992         |\n",
            "|    iterations           | 271         |\n",
            "|    time_elapsed         | 4474        |\n",
            "|    total_timesteps      | 4440064     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004185117 |\n",
            "|    clip_fraction        | 0.0615      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.557      |\n",
            "|    explained_variance   | 0.977       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25.2        |\n",
            "|    n_updates            | 1080        |\n",
            "|    policy_gradient_loss | 0.00079     |\n",
            "|    value_loss           | 74.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 256          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 993          |\n",
            "|    iterations           | 272          |\n",
            "|    time_elapsed         | 4487         |\n",
            "|    total_timesteps      | 4456448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044590933 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.573       |\n",
            "|    explained_variance   | 0.964        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.07         |\n",
            "|    n_updates            | 1084         |\n",
            "|    policy_gradient_loss | 5.39e-05     |\n",
            "|    value_loss           | 112          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 234          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 993          |\n",
            "|    iterations           | 273          |\n",
            "|    time_elapsed         | 4499         |\n",
            "|    total_timesteps      | 4472832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036340575 |\n",
            "|    clip_fraction        | 0.0539       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.586       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.978        |\n",
            "|    n_updates            | 1088         |\n",
            "|    policy_gradient_loss | 0.000793     |\n",
            "|    value_loss           | 5.11         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 273          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 994          |\n",
            "|    iterations           | 274          |\n",
            "|    time_elapsed         | 4512         |\n",
            "|    total_timesteps      | 4489216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026659237 |\n",
            "|    clip_fraction        | 0.0231       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.569       |\n",
            "|    explained_variance   | 0.947        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.22         |\n",
            "|    n_updates            | 1092         |\n",
            "|    policy_gradient_loss | 0.000143     |\n",
            "|    value_loss           | 106          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4500000, episode_reward=282.97 +/- 14.37\n",
            "Episode length: 225.20 +/- 13.41\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 225          |\n",
            "|    mean_reward          | 283          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4500000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034187376 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.526       |\n",
            "|    explained_variance   | 0.975        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 171          |\n",
            "|    n_updates            | 1096         |\n",
            "|    policy_gradient_loss | -0.000213    |\n",
            "|    value_loss           | 71.9         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 232      |\n",
            "|    ep_rew_mean     | 279      |\n",
            "| time/              |          |\n",
            "|    fps             | 995      |\n",
            "|    iterations      | 275      |\n",
            "|    time_elapsed    | 4527     |\n",
            "|    total_timesteps | 4505600  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 229          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 996          |\n",
            "|    iterations           | 276          |\n",
            "|    time_elapsed         | 4539         |\n",
            "|    total_timesteps      | 4521984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033605099 |\n",
            "|    clip_fraction        | 0.0547       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.557       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.12         |\n",
            "|    n_updates            | 1100         |\n",
            "|    policy_gradient_loss | 0.00141      |\n",
            "|    value_loss           | 4.53         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 222          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 996          |\n",
            "|    iterations           | 277          |\n",
            "|    time_elapsed         | 4552         |\n",
            "|    total_timesteps      | 4538368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039612423 |\n",
            "|    clip_fraction        | 0.0386       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.544       |\n",
            "|    explained_variance   | 0.972        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.69         |\n",
            "|    n_updates            | 1104         |\n",
            "|    policy_gradient_loss | 0.00061      |\n",
            "|    value_loss           | 42.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 232         |\n",
            "|    ep_rew_mean          | 275         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 997         |\n",
            "|    iterations           | 278         |\n",
            "|    time_elapsed         | 4564        |\n",
            "|    total_timesteps      | 4554752     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003928563 |\n",
            "|    clip_fraction        | 0.0346      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.546      |\n",
            "|    explained_variance   | 0.954       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.95        |\n",
            "|    n_updates            | 1108        |\n",
            "|    policy_gradient_loss | 1.54e-05    |\n",
            "|    value_loss           | 131         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 219          |\n",
            "|    ep_rew_mean          | 282          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 998          |\n",
            "|    iterations           | 279          |\n",
            "|    time_elapsed         | 4576         |\n",
            "|    total_timesteps      | 4571136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055401917 |\n",
            "|    clip_fraction        | 0.0497       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.551       |\n",
            "|    explained_variance   | 0.968        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.75         |\n",
            "|    n_updates            | 1112         |\n",
            "|    policy_gradient_loss | 0.000479     |\n",
            "|    value_loss           | 65.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 223          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 999          |\n",
            "|    iterations           | 280          |\n",
            "|    time_elapsed         | 4588         |\n",
            "|    total_timesteps      | 4587520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041097263 |\n",
            "|    clip_fraction        | 0.0467       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.542       |\n",
            "|    explained_variance   | 0.968        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.91         |\n",
            "|    n_updates            | 1116         |\n",
            "|    policy_gradient_loss | 0.000761     |\n",
            "|    value_loss           | 81.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4600000, episode_reward=282.60 +/- 19.49\n",
            "Episode length: 227.40 +/- 15.11\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 227        |\n",
            "|    mean_reward          | 283        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 4600000    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00347308 |\n",
            "|    clip_fraction        | 0.0422     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.555     |\n",
            "|    explained_variance   | 0.963      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.72       |\n",
            "|    n_updates            | 1120       |\n",
            "|    policy_gradient_loss | 0.000553   |\n",
            "|    value_loss           | 95.1       |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 226      |\n",
            "|    ep_rew_mean     | 280      |\n",
            "| time/              |          |\n",
            "|    fps             | 1000     |\n",
            "|    iterations      | 281      |\n",
            "|    time_elapsed    | 4602     |\n",
            "|    total_timesteps | 4603904  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 236          |\n",
            "|    ep_rew_mean          | 268          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1001         |\n",
            "|    iterations           | 282          |\n",
            "|    time_elapsed         | 4615         |\n",
            "|    total_timesteps      | 4620288      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039886534 |\n",
            "|    clip_fraction        | 0.0523       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.555       |\n",
            "|    explained_variance   | 0.996        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.3          |\n",
            "|    n_updates            | 1124         |\n",
            "|    policy_gradient_loss | 0.000834     |\n",
            "|    value_loss           | 7.29         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 222         |\n",
            "|    ep_rew_mean          | 279         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1001        |\n",
            "|    iterations           | 283         |\n",
            "|    time_elapsed         | 4627        |\n",
            "|    total_timesteps      | 4636672     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002544145 |\n",
            "|    clip_fraction        | 0.0232      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.562      |\n",
            "|    explained_variance   | 0.936       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 41.8        |\n",
            "|    n_updates            | 1128        |\n",
            "|    policy_gradient_loss | -0.000485   |\n",
            "|    value_loss           | 180         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 226         |\n",
            "|    ep_rew_mean          | 279         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1002        |\n",
            "|    iterations           | 284         |\n",
            "|    time_elapsed         | 4640        |\n",
            "|    total_timesteps      | 4653056     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004631199 |\n",
            "|    clip_fraction        | 0.0558      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.546      |\n",
            "|    explained_variance   | 0.971       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.35        |\n",
            "|    n_updates            | 1132        |\n",
            "|    policy_gradient_loss | 0.00189     |\n",
            "|    value_loss           | 38.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 230         |\n",
            "|    ep_rew_mean          | 277         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1003        |\n",
            "|    iterations           | 285         |\n",
            "|    time_elapsed         | 4652        |\n",
            "|    total_timesteps      | 4669440     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004650199 |\n",
            "|    clip_fraction        | 0.0413      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.535      |\n",
            "|    explained_variance   | 0.947       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 198         |\n",
            "|    n_updates            | 1136        |\n",
            "|    policy_gradient_loss | 0.000523    |\n",
            "|    value_loss           | 144         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 236         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1004        |\n",
            "|    iterations           | 286         |\n",
            "|    time_elapsed         | 4667        |\n",
            "|    total_timesteps      | 4685824     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004368004 |\n",
            "|    clip_fraction        | 0.0624      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.569      |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.64        |\n",
            "|    n_updates            | 1140        |\n",
            "|    policy_gradient_loss | 0.000181    |\n",
            "|    value_loss           | 4.27        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=4700000, episode_reward=269.93 +/- 20.83\n",
            "Episode length: 218.40 +/- 14.58\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 218         |\n",
            "|    mean_reward          | 270         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 4700000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003516419 |\n",
            "|    clip_fraction        | 0.0422      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.576      |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.44        |\n",
            "|    n_updates            | 1144        |\n",
            "|    policy_gradient_loss | 0.00116     |\n",
            "|    value_loss           | 5.24        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 251      |\n",
            "|    ep_rew_mean     | 273      |\n",
            "| time/              |          |\n",
            "|    fps             | 1004     |\n",
            "|    iterations      | 287      |\n",
            "|    time_elapsed    | 4680     |\n",
            "|    total_timesteps | 4702208  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 227          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1005         |\n",
            "|    iterations           | 288          |\n",
            "|    time_elapsed         | 4693         |\n",
            "|    total_timesteps      | 4718592      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029992147 |\n",
            "|    clip_fraction        | 0.0311       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.534       |\n",
            "|    explained_variance   | 0.964        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 21.8         |\n",
            "|    n_updates            | 1148         |\n",
            "|    policy_gradient_loss | -0.000251    |\n",
            "|    value_loss           | 64.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 230         |\n",
            "|    ep_rew_mean          | 274         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1005        |\n",
            "|    iterations           | 289         |\n",
            "|    time_elapsed         | 4707        |\n",
            "|    total_timesteps      | 4734976     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003377593 |\n",
            "|    clip_fraction        | 0.0313      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.566      |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 134         |\n",
            "|    n_updates            | 1152        |\n",
            "|    policy_gradient_loss | 0.00057     |\n",
            "|    value_loss           | 144         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 245         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1006        |\n",
            "|    iterations           | 290         |\n",
            "|    time_elapsed         | 4720        |\n",
            "|    total_timesteps      | 4751360     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005124023 |\n",
            "|    clip_fraction        | 0.0547      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.57       |\n",
            "|    explained_variance   | 0.983       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.18        |\n",
            "|    n_updates            | 1156        |\n",
            "|    policy_gradient_loss | 0.0014      |\n",
            "|    value_loss           | 34          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 227          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1007         |\n",
            "|    iterations           | 291          |\n",
            "|    time_elapsed         | 4732         |\n",
            "|    total_timesteps      | 4767744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043994156 |\n",
            "|    clip_fraction        | 0.0645       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.546       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.05         |\n",
            "|    n_updates            | 1160         |\n",
            "|    policy_gradient_loss | -0.000949    |\n",
            "|    value_loss           | 11.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 218          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1008         |\n",
            "|    iterations           | 292          |\n",
            "|    time_elapsed         | 4745         |\n",
            "|    total_timesteps      | 4784128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045198984 |\n",
            "|    clip_fraction        | 0.0514       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.551       |\n",
            "|    explained_variance   | 0.978        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.8         |\n",
            "|    n_updates            | 1164         |\n",
            "|    policy_gradient_loss | 0.000413     |\n",
            "|    value_loss           | 74.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4800000, episode_reward=283.71 +/- 17.92\n",
            "Episode length: 219.50 +/- 9.75\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 220          |\n",
            "|    mean_reward          | 284          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4800000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021233829 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.526       |\n",
            "|    explained_variance   | 0.954        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 307          |\n",
            "|    n_updates            | 1168         |\n",
            "|    policy_gradient_loss | -5.95e-06    |\n",
            "|    value_loss           | 107          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 219      |\n",
            "|    ep_rew_mean     | 274      |\n",
            "| time/              |          |\n",
            "|    fps             | 1008     |\n",
            "|    iterations      | 293      |\n",
            "|    time_elapsed    | 4758     |\n",
            "|    total_timesteps | 4800512  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 225         |\n",
            "|    ep_rew_mean          | 274         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1009        |\n",
            "|    iterations           | 294         |\n",
            "|    time_elapsed         | 4771        |\n",
            "|    total_timesteps      | 4816896     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003497656 |\n",
            "|    clip_fraction        | 0.0406      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.52       |\n",
            "|    explained_variance   | 0.961       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 86.9        |\n",
            "|    n_updates            | 1172        |\n",
            "|    policy_gradient_loss | 0.00026     |\n",
            "|    value_loss           | 137         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1010         |\n",
            "|    iterations           | 295          |\n",
            "|    time_elapsed         | 4784         |\n",
            "|    total_timesteps      | 4833280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043021385 |\n",
            "|    clip_fraction        | 0.0491       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.537       |\n",
            "|    explained_variance   | 0.984        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.52         |\n",
            "|    n_updates            | 1176         |\n",
            "|    policy_gradient_loss | 0.00137      |\n",
            "|    value_loss           | 35.7         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 222         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1011        |\n",
            "|    iterations           | 296         |\n",
            "|    time_elapsed         | 4795        |\n",
            "|    total_timesteps      | 4849664     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003947495 |\n",
            "|    clip_fraction        | 0.0529      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.562      |\n",
            "|    explained_variance   | 0.987       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.48        |\n",
            "|    n_updates            | 1180        |\n",
            "|    policy_gradient_loss | 0.000605    |\n",
            "|    value_loss           | 17.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 213          |\n",
            "|    ep_rew_mean          | 284          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1012         |\n",
            "|    iterations           | 297          |\n",
            "|    time_elapsed         | 4807         |\n",
            "|    total_timesteps      | 4866048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034255106 |\n",
            "|    clip_fraction        | 0.0528       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.518       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.66         |\n",
            "|    n_updates            | 1184         |\n",
            "|    policy_gradient_loss | 0.000626     |\n",
            "|    value_loss           | 6.03         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 238          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1012         |\n",
            "|    iterations           | 298          |\n",
            "|    time_elapsed         | 4820         |\n",
            "|    total_timesteps      | 4882432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041789506 |\n",
            "|    clip_fraction        | 0.0548       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.52        |\n",
            "|    explained_variance   | 0.992        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.89         |\n",
            "|    n_updates            | 1188         |\n",
            "|    policy_gradient_loss | 0.000171     |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1013         |\n",
            "|    iterations           | 299          |\n",
            "|    time_elapsed         | 4832         |\n",
            "|    total_timesteps      | 4898816      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037409167 |\n",
            "|    clip_fraction        | 0.0481       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.517       |\n",
            "|    explained_variance   | 0.996        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.53         |\n",
            "|    n_updates            | 1192         |\n",
            "|    policy_gradient_loss | 0.000688     |\n",
            "|    value_loss           | 6.13         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4900000, episode_reward=275.20 +/- 22.68\n",
            "Episode length: 218.10 +/- 13.12\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 218          |\n",
            "|    mean_reward          | 275          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4900000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039902106 |\n",
            "|    clip_fraction        | 0.0519       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.531       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.17         |\n",
            "|    n_updates            | 1196         |\n",
            "|    policy_gradient_loss | 0.000698     |\n",
            "|    value_loss           | 4.96         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 217      |\n",
            "|    ep_rew_mean     | 278      |\n",
            "| time/              |          |\n",
            "|    fps             | 1014     |\n",
            "|    iterations      | 300      |\n",
            "|    time_elapsed    | 4845     |\n",
            "|    total_timesteps | 4915200  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 237          |\n",
            "|    ep_rew_mean          | 282          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1015         |\n",
            "|    iterations           | 301          |\n",
            "|    time_elapsed         | 4858         |\n",
            "|    total_timesteps      | 4931584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036284237 |\n",
            "|    clip_fraction        | 0.0423       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.535       |\n",
            "|    explained_variance   | 0.986        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.44         |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | 0.000775     |\n",
            "|    value_loss           | 23.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 227         |\n",
            "|    ep_rew_mean          | 280         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1016        |\n",
            "|    iterations           | 302         |\n",
            "|    time_elapsed         | 4869        |\n",
            "|    total_timesteps      | 4947968     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003734725 |\n",
            "|    clip_fraction        | 0.0432      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.53       |\n",
            "|    explained_variance   | 0.99        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.76        |\n",
            "|    n_updates            | 1204        |\n",
            "|    policy_gradient_loss | 6.79e-05    |\n",
            "|    value_loss           | 12.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 217         |\n",
            "|    ep_rew_mean          | 282         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1016        |\n",
            "|    iterations           | 303         |\n",
            "|    time_elapsed         | 4882        |\n",
            "|    total_timesteps      | 4964352     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003113151 |\n",
            "|    clip_fraction        | 0.034       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.52       |\n",
            "|    explained_variance   | 0.978       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.795       |\n",
            "|    n_updates            | 1208        |\n",
            "|    policy_gradient_loss | 0.00115     |\n",
            "|    value_loss           | 71.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 220          |\n",
            "|    ep_rew_mean          | 287          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1017         |\n",
            "|    iterations           | 304          |\n",
            "|    time_elapsed         | 4894         |\n",
            "|    total_timesteps      | 4980736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038312427 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.534       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.96         |\n",
            "|    n_updates            | 1212         |\n",
            "|    policy_gradient_loss | 0.00156      |\n",
            "|    value_loss           | 3.32         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 230         |\n",
            "|    ep_rew_mean          | 283         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1018        |\n",
            "|    iterations           | 305         |\n",
            "|    time_elapsed         | 4906        |\n",
            "|    total_timesteps      | 4997120     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004115087 |\n",
            "|    clip_fraction        | 0.0413      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.516      |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.37        |\n",
            "|    n_updates            | 1216        |\n",
            "|    policy_gradient_loss | -2.24e-05   |\n",
            "|    value_loss           | 4.71        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=5000000, episode_reward=272.50 +/- 21.26\n",
            "Episode length: 225.40 +/- 15.93\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 225          |\n",
            "|    mean_reward          | 273          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 5000000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034182398 |\n",
            "|    clip_fraction        | 0.0361       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.518       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.42         |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | -0.000244    |\n",
            "|    value_loss           | 5.72         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 226      |\n",
            "|    ep_rew_mean     | 278      |\n",
            "| time/              |          |\n",
            "|    fps             | 1019     |\n",
            "|    iterations      | 306      |\n",
            "|    time_elapsed    | 4919     |\n",
            "|    total_timesteps | 5013504  |\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Імпорт бібліотек\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "\n",
        "# Функція для відображення відео\n",
        "\n",
        "def display_video(frames, filename='lunar_lander.mp4'):\n",
        "    \"\"\"\n",
        "    Створює та відображає відео із списку кадрів\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "        return [patch]\n",
        "\n",
        "    anim = animation.FuncAnimation(\n",
        "        plt.gcf(), animate, frames=len(frames),\n",
        "        interval=50, blit=True)\n",
        "\n",
        "    anim.save(filename, fps=30, extra_args=['-vcodec', 'libx264'])\n",
        "\n",
        "    with open(filename, 'rb') as f:\n",
        "        video_file = f.read()\n",
        "\n",
        "    video_url = f\"data:video/mp4;base64,{base64.b64encode(video_file).decode()}\"\n",
        "    return HTML(f\"\"\"\n",
        "    <video width=600 controls>\n",
        "        <source src=\"{video_url}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\")\n",
        "\n",
        "# Спробуємо завантажити найкращу збережену модель\n",
        "try:\n",
        "    model = PPO.load(\"logs/best_model.zip\")\n",
        "except Exception as e:\n",
        "    # Якщо модель не знайдено, створюємо тимчасову\n",
        "    env = gym.make(\"LunarLander-v3\")\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "    model.learn(total_timesteps=10000)\n",
        "    env.close()\n",
        "\n",
        "# Створюємо середовище для запису відео\n",
        "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
        "\n",
        "frames = []\n",
        "observation, info = env.reset()\n",
        "done = False\n",
        "max_steps = 1000\n",
        "step = 0\n",
        "\n",
        "# Симулюємо один епізод і збираємо кадри\n",
        "while not done and step < max_steps:\n",
        "    action, _ = model.predict(observation, deterministic=True)\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    frame = env.render()\n",
        "    if frame is not None:\n",
        "        frames.append(frame)\n",
        "    done = terminated or truncated\n",
        "    step += 1\n",
        "\n",
        "env.close()\n",
        "\n",
        "# Створюємо та відображаємо відео\n",
        "if frames:\n",
        "    video_html = display_video(frames)\n",
        "    display(video_html)\n",
        "else:\n",
        "    print(\"Не вдалося зібрати кадри для відео.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "t5IruqLC2CGF",
        "outputId": "c204fc81-aacd-4ce4-9624-61d0db047c76"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <video width=600 controls>\n",
              "        <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAb89tZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MyByMzA2MCA1ZGI2YWE2IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMSAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAFemWIhAA3//728P4FNjuY0JcRzeidMx+/Fbi6NDe9zgAAAwAAAwAACNCLwW1jsC2M+AAABahEtshMdFhCR9JZmnaKnDg+r0Fy5FpC6fMwq8XOQ/31hhxGnjxi0zyVTyYeiJZmBQqenjh5+Qr02cZS1H8blO+IQg+0Jdf6Slqg2uChMKYVYhoqFqB/+XqEkDAndnoOFdZiUOeYaMeEa4fPnN5/8d+Lnev3syBFBeZviGdrjqYIuScwWmqrI4+SdTjo/mbZsOgX0vXQDoMuJWPvytRcFdfG9rfqChLyYdkOwByiBX4N/2FsbUjpwJrgD2PTgMAxfLiQl8BOorxDgF8KEWYohykiAzDvoRlc+9lXHjUBlNnQkkxJ1X8zaWBD3T34v1Dj1RggCzqbEt7eeRAeoiq9ldJEMeOpPTEzd4MwIMakpa/G0jrhKuN3D8dCYdtu8YZCyL6DlCMLg26yQi3q8uXGmm6EOAVqpL3iEhobd9K3fsSIjsGcEt2fpvvrwe+6mxPi3Kw7kPwCBXxdv9ptw8+jCyMnDYgvp2IVtEzYOsap6eEfyUpJrVDnM6TDf4PnSjhtgBeSnSv4lyR76HK6b7gE+JFAQW4jp/qnM7ePvpWPboPTkEoOpFO6iUIzQG3qxh2/dAfL5pNIUMcOiJRfi3RtRqS2RpMyK/TfOPoPax01YDJo2Xlcp9VwrUDr/H+uK+kZ/BnLdvLcFHnY8qzqyrclD42eJjn/HIZVrkS4cyZYHAY6y+3yuJOtgL4QgHvoHsTqagn2wiSwJBKATgSewmmg8pXyExwvin09MzaYfGyoFydIRWGYY9pEv1gOZZKP952DxVL280BcTGDlSbwcTLwNKCZgzcWhq3eSKNlVJ8IuK8dRTB+cYix7OAW0PsBeXBYz7yeEqTVa/0NrpETmioJLh7rOMOZ8oaalLU3wqk4/nVOM4rizE3BEFds1jWvbYi+ckXArXeUCjWW/ww6eQT8iUM3tQr+eL4+sFOvossE15QhsEd6s+Xqn0I0atL9SfXA4B24uN8aJcNwgPCiQX+PPZU8PBTSum8iDyyYW44Zp1MJhS3cY8Qu13vkIfUrMNo5OCWMxMKrHeGN2ktLMJbE90s6GWLZWP2CMjDI0peTeyVih8XrYXWHCLH2+CrR8w5ulAwhGaYvxNxbgaWFGenntUVoxN7oI1Jv/LyC7kqtvDrknVpjyx/requWr1Lz0gxL02YEqiyCBXmJURDeQuNVTTo2fVyqHkJr0uVjSjjDD76VCOq1NMJNBNGoeeFpE9Ipzk5RY9wfhqnC7Vg9pMywPth6x566uOn0lRNyJhxLrr+SqqR9R6ug1gYcl4ICxU/8mhXVfqeea+mrvUSLVgIYkrb6eDoKH2txlc7vDg6BLErXe/XpvTMYZ19xhvvvzya4XE61TP0Yzz+f+QjuhbtqGvdOg66ArN+1UveVmOjwVReslt5ccftKZeELMIU3JCxuwB6M2RhdL4jjzhZjkNOy/xwx8effF2HiZoN5yC1tQj+5NJ3W5Kqdg3YmX0j836ODvTzDavnQhqLjx2T52gXteshoRNzoz7gZxIwB4No+8pTeO4XHGrqa3rk1lneKu4DBLnQiMQuGm6mYySrFxcPyI/Fwc3VpIesZ6PlxRgLnP3P8VYf15eTNKdQyx432TmAaun6I7k1yrxvBBYS4ss965LyvM4b8Xj9riadJNrSSbGanRwTn/4RzwooGeTSK9XIofjwqmGIooyB4uQFhZ8oU2hotCufRlPX48L1iynot6etCVaI/2CIGf5y/o7ajVLGjJvCj3/VbWYn8e2Z9fdQLr6r4AKnY4rtEKQexSPl0i/aB38l9Qs9bAAABGsAaoBGgD4gAAAwAAFDEAAAB5QZokbEN//qeEAEG+mVGVwg4lOm/2f+CLTeFslv6FU+5Hl61Q/ya5hBKqamZOF1TkZrKrZFqg5OGKCuTWgjC+GX5Fb6hczQMDNp5jeoSlhYjNLG4WuF9pVMZ9KEQuJEeMliG//dOhP/6Lgpcn1JecBJfCWBVy3cbBxwAAAExBnkJ4hX8ANgGKTwAtZI0hptsPO3Asf+EZjWokFihPXuMAWhkwgT41t5BBuDcFTK8om39jWUQzInaAUdZegMBWUZuOjCoQY38UuAdNAAAAKQGeYXRCfwBFeo411xjrCri6aSxihACt9ZVk8MBWPr6+uSpHoJVmwCkgAAAAKQGeY2pCfwBFYgnO9ytIgxSAD9oA4y2q4YNLci6BioodSaoYQtFoIBbRAAAAY0GaZkmoQWiZTBTw3/6nhAA/f8zxxdMXgBmhC73QFaggY4ZbUesSz5g9Ux8f/OnCG2fRLwFLXk/K1pIoAg19RjZzYwBKxXKXxl8TaRVvcU4J00NJSA4gjDA9A9Pgb74sNwvJpQAAACIBnoVqQn8AQ1zUY1xvZhaOYBAk4zTg3AJRngJKMhEAgGpBAAAAXkGaiknhClJlMCG//qeEAD9gsLqkAJUmD9PrYtSG8fIK6HmEPO3JSGO+z33/yhSqrXj4a5EzFZKmCQq1qZmq+wTI9ruuaSZc0POjHk19AVvFVXW69KHmJCD4tcC+tZEAAAAvQZ6oRTRMK/8ANKcK1JxoAERR+9tcL2BEZguDfxbrmAQKxdiYABZJknW2mrJ+CPgAAAAnAZ7HdEJ/AENM0BdHBiIE4ALBHBciDP9gcwCB+fGg2bQX3xSSIAVsAAAAJQGeyWpCfwBDhGqw2gBaGGeHiWYvxUuYA/ixtarFgJoD0GP+BU0AAABxQZrOSahBaJlMCG///qeEAD9gtLX4AJvf/FfIORlUcR6fk9orPrsPHUBxwgCME1TfPuy7K1Yb8xUN0p8SYu9rY68z6uAsbcxVjPfaCx3Q5lW8j7AI9tBYptBfuzYeDDxM3cLKJAGIumZgTFkIX2qtvYAAAAAzQZ7sRREsK/8ANK7wl9MMAGsMvwKtrsP4E1bM9a5wSOWDmr/3daYBoH5tkAXcLMiqHAMqAAAAIQGfC3RCfwBDaiVFzqAAt+NQPmwhP25gECI/XlPV1yBbQQAAACYBnw1qQn8AQ0zCqqvQASs1S8GZClAU/4ToFgOuz+pRsHGERACVgQAAAJNBmxJJqEFsmUwIb//+p4QArPvCfGyEdCy/JAEeiijk3COR3HnxB2A8hsXwqhf8E6MhRk7t4rBVg8Hwts+yXOHzdyMcx0Vdywq54JrYws0EAykKLds5pyMSbSI3Iv67qaN5HOfeYXBKN0IaoL3EZFYmv8Scey9t+bAr998XKc9Q863YAhf3Kv7tNq2Lot1PsOU4x5sAAAA3QZ8wRRUsK/8ANMEveHIAOMygRCelgCULpOVLFu7EIKF2KOI73FiZaLoGQp/hyWENMiaMGQcCkgAAACABn090Qn8ARX1gizdF5N6TapANact+SKf0A+IN2TDZgAAAACkBn1FqQn8ARWIB0cv5lCjeAExc7bXHy/t47Z+/Cpk0/oB8PWip0yA3oQAAALFBm1ZJqEFsmUwIb//+p4QAP78DBJZdP71MiuBBoqbdgQm7hZJsN3I5mHM/1Bz7gtDVGLnLaV178IPDrZuElWokk8KEU/hi2nun/YIZGjV+EndxRtWLEd7CGq51aTuvcnglPjVkkzxqTjF1Epm92GYmYO8zkRNb+1TUsFTRIa8erPF3fFYXam/yezosydMgXNyVMHu8TENWtrxYr/00BSNYDIvGNazhbc4/6MugKLCjDjAAAAA0QZ90RRUsK/8ANMGfsmWZ8chwRAB9Tv3pwWhyJ+P/Q+CmkBPcVpoR9ICC//2CvonusuBxwAAAACsBn5N0Qn8AQ2rHlBhIRw5uAA9/JfjolFMvX7SzeQM3quHZCJuA4to9+hdxAAAAIQGflWpCfwBDXRsyEDgGqTz/ZSg0ZnrIx4SPDAT684wJuAAAAKFBm5pJqEFsmUwIb//+p4QAqHvCgQ742SjvBHa3TEEBuT2w/bJBOjOGMvfiax/BxwhXjkKUB9jZdfhzyAHquy+b6DuisLbxJrlk6LHH4Rf0AlCH6Fo+AgB4ICRmfO3ftlpqcrXhTJNKKhyYaszxCos9SX6g6bEabnUKt62YfdG1oQ320pVqg/68cSYwWH2KFGK8pL51pOKcqn34AsaTe6ACywAAAD5Bn7hFFSwr/wA0w/oFuqn0ACcewK/mD0oinu3wfXKv2KW1BlFVSrWV0Flf4nFUtTzKuCh6ADq6fv8BJIAccQAAACwBn9d0Qn8AQGO8m7/NzSsIE3QAfkgkybbQyfXEk1lbx38lIVhn6WvWgAAIOAAAACUBn9lqQn8AQTqtz7onVFTzGD3ZNmcyHqlc4ClLwSRQjDAAAH+BAAAAukGb3UmoQWyZTAhv//6nhAA+Waf+BnPgDbHzOU518MRZqJimhyzMxwT8lNg7qmBMC37KQvNeLm3cqueoFGI6mFhU5USkUJ057iMu3kGe3G7JJAzskHTMKOiqGeLaVsGGrDwWFtJzOtKuLoYbwN8wIu7mYRABJkTqR+d6Nt5GVUh0BsIyk/ccgF32hkKF2swpcyki1ohVUK6ds9wfGZZb5JdDYGT3gtSrbVBRUFFOilMv965taRL5hKv0wAAAADVBn/tFFSwr/wAzbvQTE+wAWv7tPMfLOIHh7GTiq7DMnLPmsEYmG/T8W+RzVq/vAwMlXkMDjwAAACcBnhxqQn8AQTvFhohSK4AE1FXnMIQZ6AoRKC2zveeigIylsAAAtoEAAADoQZoBSahBbJlMCG///qeEAEG3O/zuNeOAFsgtTJahX/IDKCf1vQ1CJO3kIPVvn3w0f65UuleJFW08KXTGstEgO7GXD0krpItBXyxSEAWv/+RrAbxqGAk4IQBBHcF24fjNp5pgkafvdN7u/KDnc/EONg31uDZ5maSkc/+V7YTl/kG0M7+YHrUgrC8TWgi1VDym0wfvrrqODQ0u2y7tuqHmICNoMrOr/Jph+PI3DTFvz+74uNY6G4CP4QQDGPKAYgK/z53pzx3HgW1jJ01pLUedgVfY6DQqQ3jZHZAufngO/J8SnMGoIWhSQAAAAFNBnj9FFSwr/wA2Do7GYAFrd8AWZVip5b522IFjpHImYl7yJsWYAGGvyWfULZGtQ+aAnDgQJJxXY+QPy92A0tcBWmABq//9vCNp/41AhHvP0oARMAAAAEcBnl50Qn8AQ32KiOAAQ9fpm7ZrauBnsmPypo4AXvYe2AjgtYU4h56om1NIr0bYFOAR1Qwx60opv4cta81O5CzgNQNFiMKhdwAAAEQBnkBqQn8ARXbLJ4IAWCc4GLBLPCyI02vD/nugnp0tqLOYUdQjKiJjqEi3l/WTojAKM1GwMc6gxAE+pLkLpRbTzGh3QAAAAM9BmkVJqEFsmUwIb//+p4QAQVbT0SUKidqkhYBaj+HNiLpmhSHsv5j4/7kyGXBVkZzo8EV+v5XFP9PDLUTdc3yLLWRfmLXKo41JQE22mywD6T64RCpiSE9GX2vwywLc0AegQoN4gdqRzfEcnZCON6lr1YnwwCS4h2sOmOAG6yP/jziRlO8xaMSYY0ak6ioM84mf06D40a3xb6Opa0iACOX/6lrz9qwwBfuQaaUpl4dpady7of1HrpMP9hrkmWh969M9XbrQ241Z5w9xPQkQ2YEAAABtQZ5jRRUsK/8AN28KIAybF7DtCGadH+KRrwObzYmw0qXLbJvlCW1lMgLkuAVc6XW+pezOZsXqyL+ah02FRXa0YvV5akqioGoPvp1OaXzjT0Vw2cIKKcgLDXLXZu517eDaCsf7Jm0Y1ShWwAA44AAAADUBnoJ0Qn8AR3/fwBxPZKxAHu1L1om8R3RuXBiVd2UdRlUvbRKTkklMA4bzXGyyd5gdAAAGzQAAAE8BnoRqQn8AR2L+1CgAGapRYnZRY9Z5zDCa+nvLDYzFa4Q74r5CFO5bghvEDw6a5Rc8KP+d0BmWQN8Ft0XqnVupzfSYvw1Lc/LMGs8gANmBAAAA/kGaiUmoQWyZTAhv//6nhAA8/vWxmrWNcjOfVuu/NcUGGRNaD/SFrO8bfdqgrIJoc1/x44GmXvJSKBjAxiWvXKwoOkX2UXCro3JH6W4Caijqg0pFaRKQYWYd0SZgenii5xjEK9P8cp58lgmfhh6z7zH/cp+7jGRs7sE9i5t9m5CM1W2thv/373DreP5wVDAg/NmUsPd9zYM0bbpnH1FuJZMhFBxvo1sGBP5gKknhJpR+QXhswoWh6jvuGR6R7qax03eHYEL/39H5EbRTqks7ZmBQK0JD2h54vUThM72Ld+ROmW7oB9Lt8/ErJDj7PusZm3sREUCjxpo1pUpUBBLxAAAAckGep0UVLCv/ADJD/26FKdaHKoxHYUc1FaZZdiWGSCws1A9MAqVEBwfmI7ATo4l+XwLql6exhwHePLRxWiGRKw9YLYLPUD7HRaLzafGjBAFvUFeZJpaeOHel6hkRKsgWsbfHPYMVYNgXPGN+PsRuSlaBnwAAAEgBnsZ0Qn8AP4fQCDy3c38xM/fkAcMYaYVTIdeXYzNvkIaa5WOzMMuO71QDk/CUm2MKLefMyK5L5BGdwgPoRjk1wyjT+CDNgz4AAABkAZ7IakJ/AD+AGzpRspBMAJ2+6uXUnkptdMDxQFIUg8STwnhZpcPlXL1pCJpkYN+QxjAEY6VbASH0zc/BqAGts8a1enPFv1G0GLzWZk/iX8mvHUtgX9Z2q8gzhEBfQ+5OBAABQQAAAQ1BmstJqEFsmUwUTDf//qeEABc8jSFJo8fqcfAANu1ArLJCs1Hsc9UuQc1x0g6CKHiuJIhOvx8ffsohz8ZxBh78ViD1EAMz+p5jjBthF6DynvsbBv5xzz/N/t8XwBGWAyToWCina9yHFo/Sn0Ldl3NXVIaabi7SBxzfpS3qQSE6CJ/0/3ZpxMIFV9NAqLo4tYNsM8nzVn6L1jluSs0mXWBxm8XN+TKe540Gi0h9bb5lkG6zZcdjCkIgmxzn11PrsvkPp9JOrKgTw+euBdl9ZqQ2zkz2EhXvpTDbnpcx631yIcskFx2dEY/mCTe1NCRpdUPDxm8GC2fhjaZQId2Dcl4DyplfGhy4qVw84sgS8QAAAHsBnupqQn8AGTXoAKSdNqbc9p7kFGdEZRUQVYbkkCiDH4Z4ZnTAd5SL5WGAEOKN/ocsPIJ+FVw43CCRiqJx8iNtpgQBof+9en/p1fVQZcwykxOVuGatWQ3QnRtgZEBvUXxxryqO1YPMViug4PEyafQq13JrlXWkecrEBbQAAACzQZrvSeEKUmUwIb/+p4QAF15l2jm8oejPMLUDf4WNhkM/TADdQ5B+ajTuBKfvwvinHd3Xdtl6JPJpsYoCeUjkmtS60VoYvb6lKFlJOnydD8cm0MW1+gkO4RpTE5bJEu4Eos0JzoB/6GgrCD6Ital/ZCGrFxfnso4wZn6TUNBT8varvAFyT2vHXzUKpUZpQpXczZgrfv/J6cdanEvMtj3Rh7wwYOvGWRKMj1Gtw//S9NjfASMAAACiQZ8NRTRMK/8AEtjRuaPP3CIDFpxx0ALDlLSx7ajqALFVD6+ISnLEs2OEf3YvQfsnPqkhZKEeq1uIJINvVcpIHuvWnz7wEanMEFYfwdCJSmx1K5N3aAgqX4S4PN5uVcboKIF3Qj+9vSjDcrZieLE7uCWcT05eDNPq+PgnecNKxBq0suRnm1zc74wO+gkOsEciJjZ1i1vNyTlg0utVlha7ADWhAAAAlgGfLHRCfwAYfP+/EGn6rnmONY8AUyDqtyMi0BKn6tpNj3GC3wZ/e6qbul3Xs5InbMEU8TtisknogKxQrWBiO9GPUs/XG+NyO6853FMcZFp0IjLVLKQ+fsX1+MGS/1waOITroxjY+2uWlM4FrbdZzFah+k3opNSe5nAWyfKKYo7JUY0/PiuNbXwrXqWM+qOxMsTCZMAF3QAAAI0Bny5qQn8AGIDwru6PwVxdBwbt9kWbkrRbL3otV8KZKw9lYgZULniIydAAQmb26Dl3MO0t9O7UA/hqOaZcGe9pjEtlwbewiRopUmBsiR3lNRW+9EGHele7zvsrTXSH/syR8RYIvcj8ip5YYs7r9CDk7Uf8F58rHcLJaarw2Gdwz+zKHUh7HtzHB4IAUkEAAAEGQZsySahBaJlMCG///qeEAAio4dij2Whtx3AA0WufwJEBCHmP/fS/aY23qUqsj8EH2XZ0pRbHpdRjG/IDQkO9l7jaYaCtscUeIIhiCN2KxaBo/7vb/+J8OIL2ectyhpmb5SO4vL8kIG7zp6/0frzJwcRLgGDVwCxiWckjNE9t6nql9b1YMdYYJsHAKglcJ5IEq4RbBl4DWhmy7Mefs+T4H4rt5lX7g4OFU3ixI140telwEW4GcXypJaVQHQbMqm7ZSyCi3TSEODS2d2ehnxGmSzDTuS3HWmErXcjHRRhbUqsUQQnhY7MsWcUVlfJoYyd9zee4mIFLZcoR9065PR9kXBL+QvM9IAAAAIhBn1BFESwr/wARYMzjuvg97AVQH3tTJb6wwU9YAo+owlTVPXm5DjK54+CGdDQI5uPH+1pExMWRVcg/UHSl0xwnGj1FrRaHO+Fj2qgdjv6SXtcHTUS49EQLMusUazI5aU2lo9OTWY1KzGq9Qzn4BObSWYbYMVXpEGEThUNm2g8l1XVP1xLTMDjgAAAAjwGfcWpCfwAJK70YbojL7t6Wl0zgAmvlcSTXYW8rhZgqvgTmIgCi90mJu8xcEAInahKA4Nk36+QemOFApA8CeTVue960NwXjHsaHjzZlDLrapdJqcXEKTJHdLytX52taHTJgZAGrkHUZlgCkzR4r+UwKTYcPxqyMddKg1oJ5F5Nx9rPPg17Qji5t4ztGTAMDAAAA8EGbdkmoQWyZTAhv//6nhAAIt8jS/6Ax0QcpnlNk8CswL5CVnxufvww5kKht8Ng/PecuyLmAq614NqUFLHgrlzn4WIqiyrecTyGDHCYLHy1/DhKzYa5R9W4qyEKk9y65AsSEy0KjwDOluBumixS0uRZLTSrys9piUMO7S/ziAiDhpk/mhmgqh1oES0R4Y8JNwmGGRgMOBW3lZYDIII2qOtvqsNufh7egYJfomwYPyiHn+0GCRUYTLd2DOWuzI8aTcC+GYXDo3O50lIdpjXTozIUVIvOvQkmwt6ct/dgCyIUq0xLWgQX72nKst2vRfagDVgAAAKdBn5RFFSwr/wARYMzjZVZl+K7mogfVKjtCAK1Ia1ts4lbhshgSJDzaEioilkK+ZG1eCR88Ag2V+b1wddZOmRKvuY3UZ4UyG/wGYkiDMKSScqoZSZnl87YQrwfRPVJA6esN29Sd8/fs2Kqe1dyhdmnY1AHPmq2w8Zwq3lyxtSYukhZfDpg+VuGdXzKcfs4Ox3qwvoG5mX/Zd0RzKh/uWvokffYEcagO6AAAAIkBn7N0Qn8ACS143dwg6CGrBcN153AFWvzRXX/kMxwCTkGkc4m7BXmlR0wX4QwyaXXfi1xY0wgAO8thpxR8WmEG7WAEJ8+xTU0qvJoVVvVCdRN9SGDGR/iUpinTUC6yHUuaJBg3/RovHbZ3AhQCSeusnj8J008QlgL5uWuV+q9b3JnsdU3zEABQQQAAAJEBn7VqQn8ACSxHXhsRSunCoj8e4AUk6mwUyYAagM9GZRL94y4yz0AzFOAEn9POlLAC0ppMbaTjJBpjyX/WjdqAayJaij9I1xjVYE/zWGQ9dGpqXQqEgtP2Dy9RgwVUuaibE49YW6A6P0/ulxzqYzgxmvK3TGRu1WTy35GS9wXeo5gtJvIA43ibKjOwOUqGgKCAAAAA3UGbuUmoQWyZTAhv//6nhAADY+ycbQOAHG934XopLkPX0SrnZdQJDgeb5024kgIUHrB1gALtQqdlYzVfII736JAmbKZzGCASQ1KhYlwHMY6HxhKd2jvn0l+mVkS4JuqsZaIaY4giUwEkPOQyhb5zdxn9coFuZ9ECX3c8UOuLxvxQcJeuiI1xFOI4M4eYf7LNxbPcpkxg5R2/12tb/kBcLum37oU5yvn8Ydug8oTrJJoDXy4/ea94BnWGNxZ2vEqQJNyQIqkqDe0x7EXCH+MgWAPkztwgmbzr1QbTTPSBAAAAiUGf10UVLCv/ABFgzKHiNWTjtoAVzNvNkA+hh+Ou7L/IP8iKhVpyUfrxYcsWbiONCKZOgM2FaFmsnt0GfpVNISJZpJRPEV/ZKdOvki2oTArQdQekc4azANiJjEupN8zdtAuDvBfW9uDRvr2LRCFxU/e88Cm7Rzw7lETTc+qGwu2Y6nhn++BAZruBAAAAiQGf+GpCfwAD4vAWrvCYAUGuLtm2E0tn0nGVSPb0v/+gIXq3584DFAp1VN54DlEg2Fgj/YnF7qhUmLcs8bx9mXOyV1M1X/jgUmk74x+BQ1fs3dN5mWDykvaLjKvf9CYEVg1yNxop+5dCPgGsU918AVmVraTJlSheeMoBm+7qiM9reOdHNs2EABSQAAAAwkGb/UmoQWyZTAhv//6nhAADT+ycwxs1f8ePllkHaof/qqfs+EALWXWhNROBCMIHk4b9tyHg5Jwmfa+biUg1zMuYY6lOJOjYvMS0vtVT0815Wysd+uH2h4W6BI1lkyw/PgjmzA5ofCagukVmTuPxK4G7qQ7DuWLWDXawp/WvZF0KQeC83uTfmDmEabXhuQFlcILaIy1myqARCQVaL9q8k3TdrRhO/bRkLVei5u37Fz63uc2d4jdtRcTlIJDNdotuWZSRAAAAi0GeG0UVLCv/ABFgzKHiNWKH4iiu14qNJZGqcIARftb2jV/eoodosQLjPlPGbVKMJcs8Jhls2gsTG17zR+CAxviWs7wcuAU5UGau2Lrpjw9tvFfr3A0GGNTQRietCLUPL0DeGtRiPSW6HY3LXuC4O+2Q6g8CVjoEVCXfb3Jg5/879GTcKhsCkkdQcsAAAAB7AZ46dEJ/AAPhr6bhZaImqdH5WfBN6dGgCEZKpZ9yjd+WwV3WJN8Aw6sq/moswled/SiGhCNhS5zKhfOXUxpKNKDdY8JPLdYABzzpkzmHGvFc8LpU9XdLqfZFTnrpfc0rPWGwpwdtIeUaGCXaydelY0JucLPQzNFdkBgRAAAAgAGePGpCfwAD4vAWLoSDF+Ix9Di/YCd/GwhbNKVex9OIzMXDQS6Ky1MyhiACTmS4NXKiBxjhs++DTrimFjVN+raxAGGUTk5S/7Qne90Y3Gq9nPyO4v8ZfOMiIQfspSKjSUEjs2d5S4dmZDuFS7i/w6M0MHDczmGDJtN60qPkGAgZAAAAuEGaIUmoQWyZTAhv//6nhAADJ8J5ovfSer103AxLRj7LTcIkXyWd2iLywAaNDTq63n+VdDcMjMBa46cM5eq+nebtYy+MmWMtL7PlOVgn+XZVG45G2a4w3n5vzY2YkptcB3AUaziEmrAt68jalu+zoIduO9RBOdXsnydMirqaNv+ukOlCA8JBbbAk+mwWx7kyHh1OvirfGPRzGs9r4j2lyjbDm8WKnLu0bDkhyXi8fTwEY6W+ggXCIgYAAABvQZ5fRRUsK/8AEWDMoeI1YN1kMKCiY8WZWYaWrmTE6bomtQAqlWv1HP9CZ286SdP2zA603us//+/LHKx3BvTynBUW6S3hXWSc8jhaB4hKDVLGJRoGL2j/gw9vl8b7H6ZlS05VZE1xD3UiXWFMFAFfAAAAewGefnRCfwAD4a+mb6UHdGAIR5Us+V1rtlF+ru1cJi+HWmh1vB2Z1BJ8P0n9qB4JcrtwUriPIH6flMgw2j+XiEdG1115n/sQAz0nMHLfXcNd3hVODTFbN9++v45yNkRnZ3BroxxUpmWdyLMZZh/MEKLKitM12T6v97wZ8QAAAGwBnmBqQn8AA+LwFKntQGbAL0P3BxEMaiEAJq7ckCKhUtBxt76TTBoIpYkm1b9OfKmiDcgj4qHG178M/H5Z7Y2jcU/uwVTxZVxhVB1TNQTVRC7esHv9PUcHWf318pftdtexuQdRm//h1LbADAgAAAC+QZplSahBbJlMCG///qeEAAE1Wc4Rs3kk2mn0ruPSAyNPe4EbNge6QAIoGPbpvSz4JU4xb6JxCBmBFMWW8u/r0RxDpbhbhlwYdUILstohPBHL3R9oIk6VbfA9k4jJQhpX1lWP9oPGq/jFhX6T0Ce1pk7bKfLloH7sO3Lb/afbxRwbm92d7mheEFZnW0af7T2vBcSfvNPqXHkC5xHFcnkZVY/xdak13w62SYUh5J3zLIXX3urB/eJ+fy8rN3RFwQAAAIlBnoNFFSwr/wARYMyh4jVYsx9laFafTaVIjSq74x6WJa3B0GQvxCH5TKwG96QBBHsqGO/sXOEHca92PvZdoCVcfLq7WOu+RTTUzEqCuojHHqcvjfmG7B2jA5RChAmXzOKi4oG7k+uktHnQTUf81qHY//j5keDkMbD3uE5VDDgqhtMEx1hHkADxgAAAAGQBnqJ0Qn8AA+GvpB88nuIg5nwaqX/HwCKlb9N+cQHprZfEJM5KYGYkMVcECWd2qm4a/YtlZ3odg4Ss5ds04V7diIM/SU4gTcOw5+szuwghgX/Cqzhyqo7EMK4Lya5sAmKJwAG9AAAAbAGepGpCfwAD4vAUqe1AZo3Kz/+mjH8a/om4ZTIu0EFe9fo3MIy54ADVRgNYMUhXLGSGrX7K+Npv/HAAWzYLD+Y5FVqTyRf7u2pszSd45FkEfejKgV3XKOz/KxRBvv/8qAte6BIA2ziWQQA44QAAAKFBmqdJqEFsmUwUTDf//qeEAAE26b2nEeRx1e6oN1nIyxiCHZHD6Kt38W2eaC01lhKbaBu2xBQDZs/i+DRsZrSwEvxfvMnerbJ0YUGtMNRinxMM1HvbH201N6LFNdVn9m5y5NOIEZ2/B7kCVSj1IC41m90JdIYXuB+mfkvtKWe/7Dt6UW8w0zsSvzSNCIyn88LHYc25UX/Q/2HH2gUkTAACPwAAAHoBnsZqQn8AAXTzvyh841h6K5zvl6WOoS3a6QoJGqdsWcl2F36ejDwj28QA49n8YYi6VVzWXmLjWhh/4vJP3iTKbgy73T4hWtb2UFqdEU6W+EQ3aTlxSkN87PLdZjqw44lg3NsZ3N82LQHff64ivN5IC7uac3bvgADFgQAAAMhBmstJ4QpSZTAhv/6nhAAAc9IPbq8uAFbiBq9zsZF1DvoH5GyK8+9ArKTso8LLYxO5VTBBo/9GTqql3v/nuqPlJnLRDp0Er+geB1Eld1nnBIcwxqlB90piHOAXPE2R2JdFwzYcElkdjkwv0Bl+TLnfIBHAqqAcOmjscF7BjnCMLlc6DFHpWAhSpw2VL4IA15nGO6vUU93YjfrkYACgT6j5389YcbsM3PgKK6r3dFCYgYDlOrwFkeQPZBfHjpIIlqzC8lERkdYMqAAAAHNBnulFNEwr/wARX1iuqSwvLLeLY7oupXq0ewG2kAJdMFiApQmRxdgOMDoGiDNZj4WgVIhFNOvADvt31nPygLY9AzQXNyaoH/83LdCJ/a5pERb4AgyDVnxpKmeb7zxKMNIL4iCyLlkt3IpBfK8UsRKtQBTQAAAAcwGfCHRCfwAD4a+kHzr+xgVG2I7mk4nSy7Gj1h6+mcxzQ7f5YaoFkS9lACEZvKqFS2xM4hYsQcVdtWmSsgEOSP7Evd+W4bkyQT/v5p63oelXtkcAB3I1wdnXEnKpSP/Lf0pIK/c/v+tGb3EcwJrSgBwcUkEAAABoAZ8KakJ/AAPi8BSp7IdfH0Z/LYCoP9rhKHZuwATDd6XNR9O0MJuF1T3zyVvutCdTKfN61e+N5CyZ3vCJuCiw8x5p0yBBG9j3Mm7aP+n6mwNj8IOvWg/oHES7WOEmo5+SHxf4mVTpRDwAAADXQZsPSahBaJlMCG///qeEAABzwNNeBNIBadNK7WfTadel6HPesU72pDK6S8F3aGt92yo02XTzyUeKxIkKZxzH/HDKD3iLebFZM8xUe2rGcCTIfCWi27EXfu+/hs1g1dFek9NdCGGkgdLYmu32EURNzFojRNSF9W8y12vBxu1Y/u1aoR4CIBEYWYQI9i18C6b0PXHnGbAc+TKmtR7D4DHkJmylKseeiG2Ln/fpmSHMcQQnKxDtpmYqGCc9lbh/cKN4jIfy+iHWR3jBbJvjvr9ulawOweDQwyoAAABiQZ8tRREsK/8AEWDMoeI1WLMbI8X2Q0IAt2s8rLiRuIiXndEKLWCVsDZOdJ38+8gdo0AON5vSlFsOSjmIwrxmudvJlMfVhFV+05P7fkx52r85GatFs4m//SBn54+h3iFQg4EAAABTAZ9MdEJ/AAPhr6QfOv7GR4tNFGdRLrzyoGRjRARpB0lnZmno5TkIeFY/Vzxu74B/nJjft5QjpBHMcctfknnJSvpkGNJZXHJ1GPxzVdxGU2zAbMEAAABbAZ9OakJ/AAPi8BSp7IdfI7aCZmOp8qttC/EIAS+qepep2Vi4IVMY1DKCJkpz1zI06zYqv98NcUw8Zyh3NNWdTfQ+8SIXUXpb/VhZg+fRVZ8I5GLEG0qbbi4g4QAAALxBm1NJqEFsmUwIb//+p4QAAHR4TOlXeyCHmeMufsAQgDBUaxYeohrsw3zgUPxrWchKPHEZ62qAur4SsHnlg8597jBd4B3OcHp88nBS6MzHr8xpoYmWuZ64QD938LbTjIpLr6gGdzq2tdqa6L3wv0Ei5SSuE+YS4iMaXLpx/Gmsu0Ix2hIrQpK71y0FAs2nErCKXgLMuvuKGWzm5DceZ/VuHSAJesq43sapjN5mVRp0nKrbPISk0jLF0J/GLAAAAGBBn3FFFSwr/wARYMyh4jVYsxsjxg2f3wej9/bFPzWo2NbD8ZkEdypRMLfVmACZ7N8GnZSUdqWjOY3uFNSCWV6pE2KSe3Y+la1h09VaVet1a7GZ/DikvVUR6AzBefj9mTcAAABnAZ+QdEJ/AAPhr6QfOv7GR2RcmvuF93/dFMLm4gjZ64YtJrBFRRFHeaX38ACw9l2cguqlM0lI1PbmpgbUwDOqcXmHzelRFEoLhMrGQa35pzetoPtNJw51cg7aasIHJugHheY6S4ilbQAAAHIBn5JqQn8AA+LwFKnsh18j10LWiUygAK4C2rykT5yJjL/S97gJcDdzDzva8Qgv8kk7slHjtDUHvp0UoyTl/EodlLQ35ZLrYzyg833Y1aFgPmZXgcNDbLiDV6Ydfs2ZQYXF9NKMZCOX6DpotGIu7r8CD0gAAADxQZuXSahBbJlMCG///qeEAAAtWWF3FgAVSVFQRCFrY54b1ZbO5A+aSDAbTXK9p7lsRvWX6fKYRnw8LH+uL+/Ees4DqiiKTgTzobEzKRChYhdIc299BeDxgDrTunWdO/7iMhvnKzJy6QNwvvG6hc36sPKcAqbo6oDNYvHD3dlSiF4zcGnJbGkpVEldt6zbh/xEt8Q0g91MRzUh4HUzpPiN9I4A6F/Bvgz98eidLbIfEF3f5PJbAUg6Y9gdSXAHFgy5lJI/Yrv4REpABI4K3YlVBHyCGgr0NCKJpCI/kqkCHBg2oFIPHASXwKW6T6uAONsB7QAAAJxBn7VFFSwr/wARYMyh4jVYsxsjxg3pXNAVPr9Cmv/KwlGo8AAawV1O4H/ZXg0pwLvVUSpfGw51cQldH0lPYj3MmJzBrELLEaRX1DjZPs3W+w2XQ4hNb2zAeTmtrV9tcd/jTrO1V6MIMM5pNt25E/l1Yck7HsndKDPasIPKL+nmZ1qYCAv/qNXDDEidYxO4WOJvcFaAdfWbDOX4CqkAAABqAZ/UdEJ/AAPhr6QfOv7GR92FCRAARiP6MJZejQNmF89BjBinvvzHfuS5huh4v+sWI/PrOKBuQAx0z04KAQj4idyKC0wEY7m+hs0f00y+okve+WC0f39/WzrKKly6ehquddmiguf7AdRB1QAAAHwBn9ZqQn8AA+LwFKnsh18j19GeVA3ULIU5TMrmRfpbADmwtIojlbZ0u4ZbRIX7UUmHdj6kXqeBW1kYtDLUL4ZW4tkgrPjCq/ZOFnywByBB9hB4VhyENoTl1mbZMWmnw2satbqP4Rzm/nWOyaFO0UjD/tUjqrZaXKn8aAVNAAAA10Gb20moQWyZTAhv//6nhAAALZzLtOIhSrvJsnRYc6q8v5AFKAJdJGNevXoNro3UxCp0gKPKw9j/BTR3oseHxHDyVHNSUDf9VxlIO9H2pT7hbH7qAb7omFKxasgxqx/eQgtNFTVPPq0xIzhjFB7qkmHLvdbRiRklGzNtJ3Xk9MXQSuz1h2E694MP6Aj4Gx0GxyO6s7SZfLTYn77c30R5DQBDhyIBsE7kudAwmoN/5NFw8AbNw4wWxL2iGw7+uSMhcweVMa3EpUwRs/NZCcsttH/b6IDp2BZRAAAAfEGf+UUVLCv/ABFgzKHiNVizGyPGDeiUop+9vUbZKcy4xpD5RACzaCA/HkO9aOdlGwiy6vDEpc+IoBS3nxpGdW2nypwJX/pmuXG0Lw8dBxrDANVzzrwXMBIwi2c01jVWfqaYcpYAt3ifMPJZ5IXyM30CBpm3RL7qWg8YAj4AAACBAZ4YdEJ/AAPhr6QfOv7GR90qe5K4m102EWpG1TjG26yCKADy6IGztuAtw0IzxYV+y4YSSG+8ewi+1zir1PXLjoQjvViIvhv9U18Vc/ADeJ/GWAiLIUSg+d8as/1oT3c+fgAcJM3ZB38VmdfiM1Hv73+evug2LXV1ldI9MIdOXBlRAAAAeQGeGmpCfwAD4vAUqeyHXyPX38fSvgK/59L7f52rkQDRdxy4UjI+Sm1l8Hnt5qnErRsiZnCrpJ4j/3YKSUIV5SsC5WBpzkJ9LYuiNFw29F4sJKt0ubn+W3gVRZUgTU+JDRkSvvi+EM60UzG+dqQMcFOyPVB+iS5AGVAAAADgQZofSahBbJlMCG///qeEAAAQ55B0NNv3TwpfXggBP4PEurbf4bpb9+C7eQL+3DY61cSvoH8bsEDBBs0tWG0EYGG+PtTgTQH0dcO/bNhejTivAAtUMnWTX6czZTTqPG6Pt2Iebtp+fj6Ks0orbZqVKsaR7gMTw4TXfk3ByoaalZHGqNYdpn/uWjgg1BSQwQmWzhRj6QE6qmTicGuS95iNuocZftkTnFDP0CR0SWjBxukU5ZNxBtY7XPTg7bQmd3rsZjI2aIcrnsoj2PdVUltBoY5cbag2Xxlmyhp+kAtkFVEAAACwQZ49RRUsK/8AEWDMoeI1WLMbI8YN79+5+kJhtVhyEwlkef/CgAh7tyfrBeuIbQyzI4DvnVaRnFZfN6spJnUM4QQsBamqwM9SA/pWhTsyotXJkVHHegMm1A7ZB23fxwyrHAVOKyEWi8BCcOI8eh+kOKBA/PU6JzJEYeyJoR6xdFUaGnKGZoU0A/3IITGpUWW9vL/+JO9DyatzgW/JvkC0C4l0IwVSPOlUObNytd2gFBEAAACXAZ5cdEJ/AAPhr6QfOv7GR+PwC58eA7qsKG3hH/OwAVzN66LAjPfu5FCi1ZXV25aGsPIaWlYQ0wZPqKqrZKmcg+P7Eur7kl4yAEcCNPEsPOchDEYeh59PO+tBreRL3gSQrN63nIh5uUhl/QradkEoH5N3wXzI8Wl94lv3sgZgCJho5rgTtyDLSrb3/fjaLMwxn1FBo8AwIAAAAHoBnl5qQn8AA+LwFKnsh18j2OU2PT0HSDUAQGnKAF5js21SZ40Lt2lt++gv81oT8en7/g78k5PV+pPYn1U32socLakSm8Iq866oQgCNUJdfC94W3eG+AoG1y8RPKpRUeGuRFVdLmu2cfE8/aQ3OL5kol7ZipcymLKAMGAAAANdBmkFJqEFsmUwUTDf//qeEAAAsfMu1EGAhXCxgAbGzZU/CZOGKogJTFRN0CT+u0V1uQJ0oqQDlRac6jQXgykZG58qAvx3P1ylFmeg50haXibFU3UQq9YPfQBxcezwspWSZYJJ5A/KWrgbsBJNZ0OaFMXQplbpytK3AHJZbBkhCeQrHxORpK1OZD25KSGVsS1sfkA7QLiCbsKD4PgTgyMbHN4CNJnoC+zv3bW7U57gUC8qgdE4VUZrs52d0pvyW8HaiM1j9CSvALoLuvQX22feoV+C/HHAjUwAAAGsBnmBqQn8AAXTzhUMqSnL3nGwfc/+dJcmm63OHTzE/j4WJP1LmEp9TMHqKVMEADj2gjGKUyHq0i5dMqk4lRYaAIMpMLtfQQK36oh63ANVd8GkIVr4LhsKRV8zKHBdlQwa0a/r3WBVXVxaCXgAAANxBmmVJ4QpSZTAhv/6nhAAAENo756SyQBHGPTXccfwNKuxhzVgglQ5+1+HLcLcCbwmOOb4Yg8impILPfBsm3E62DQfqrvgwwk2Fqg6H/w5enIyvTU7anlIPqE3rNH+yypK3/CWgnXYamnuuDO6XVQIxFXllm3qu19ksFi12ZgYpsZe1fcjkvVHSwQhrSQsFaEAqBJQxwYGzqTq8A4XRGBG4RMHDPi6eQSUtVZ3QsF+GSDp1lzcAeF/pPee4eCd4g/wOZHna3whEwky3pyWV056rugzSAcmyas3MhBjRAAAAi0Geg0U0TCv/ABFfWK6pLC8st55ng3jxekemhlVPD/fwAcbupwPdczYqw7AsiZ8cLZZ8DXdkFxxfygf97gTyTasuZmRs+FldZ5Svw0fj6E74KM8sDTz/D97m8xMhYyRTZE9vQGavidSpWa+kSYSCOr1JQy7ORI2SJZwU9XEwo4xJai4T9OJ/EI5Eg+4AAAB/AZ6idEJ/AAPhr6QfOv7GR+CEdfvOoYSbnYWxTpgYbZ0IAB5hb4C3rjIMzwj3OrjXQhy9vptIBnAHzv8SJpkpqSSSOvq+w5pZIQyAn8g9sLwmW3Ifd9GdGmT0Z71HyLE6qm4g8puZk8GAOyPazVw5tBPNBDLu49cZeIHXO0QBLwAAAIcBnqRqQn8AA+LwFKnsh18j2OSuRD88zCDC4b4oACCT233awtAl5//soXR+/L2Bsju/1KS8HUytWoDI7cBtEp//Mh8CrSAsf1FZL4Ds8Int8/6mS46f85SEmQgxvguchgamLhQucXGcL7ovw8olyDX2G8Q0NW5Nc1cbTrJozRQUhVF5k6xEmu8AAAC7QZqpSahBaJlMCG///qeEAAAQ7pvaOb1iyc1OwqBh3pPLBkiAFjN5ngUssS4NqwNEWfgB8wXWDuPj0dP/Ckxh/o6VQUgPCIggOZQDVQ1Kv0zGeGB+vRbw7GWca0R+n8mYJQXiIclUXQ6y+URNJh9R+q+HB9QTXmJ47BhIpNi2NU2dbfslrBmCDhBsdWf0R/CPu5sLAgObdM1LhAz4KlgDYkca+M3doVcbm4/m7zmYoLGo/3uUB9qfD84SsQAAAIVBnsdFESwr/wARYMyh4jVYsxsjxg3sx/ZLJVB2eGfIbtvbnG+mzdA5Vq5wm9fRe3D4sBotFNCl9+nM25I1ZP5TUtJmMC1XTvdx7F4I+Fe+eRPpSVIv81MRo2ZCI8gjpKJ5HO8uPiR2Jc/Myee2jd2sFRRaZJy43RXU3dkuQ2MUAoAjOBRRAAAAbwGe5nRCfwAD4a+kHzr+xkfggjqDBZfWAAV3Aj9uzWjjuKD7awlSH6fAsziiLoNJvfE3bq1RhOZFGulC8X3jnxNtDydk7KqFo2LJEV77xY0OeP/cL37pL2f9ui+iszx51t8/5yFiznyj/IGYaXzHpAAAAIwBnuhqQn8AA+LwFKnsh18j2OUE43NuD2+03gCXXIX0dz1i91bxMidO/c1GsDB+7iTXjBO3Mrd8gpp45GBTu5dgsSSi5b/I7xpT8RSUmILBlNKLaIgFGY5anMwF7rKYp+pNINGMueMNPJilH/Zu0VRSUX1OBohW01QggeYKjqzDFjTftTeu3nDVj4DjgAAAANZBmu1JqEFsmUwIb//+p4QAAAZ0D+pS/fJy7zIMlq4AoiS7XRZ7We1u8ejeu9JeLArZqrtQiPZVhaVBnjls02M7KbyP2FvFlQtEEadepALL/ogIjaht2jnPCS+qMcenjYdZDLhVdmHvWdIVv41k8zDaaTYEwsmtT+mqdj3yWEBvAZqNWDaiYdcRpaTXavBOpYGzoWc2MXLIXxx4yuNkOuTX609VgLH79Qh0+iIEuc+j+k6v5H38EHqqShXGOG3PonTpeoIxe7iLS+Xu9VzggYDfPAZxeC2hAAAAikGfC0UVLCv/ABFgzKHiNVizGyPGDeuCWAiV/RdD25h/zEAIq6EKPQo5cgXuPEXA+noVSNRVYeRVdbsY1laYHCoCcxUSfFhvtvLrKzasfYo7I3ad2TjMrE+3qHao5/LTt24X+Jw3yvbbPGMT5Y55pGEUmLYienv95dD9DAn1T7PO2U3q+kmUmMjhUwAAAIkBnyp0Qn8AA+GvpB86/sZH3wmqL+HoXamKWfwsiKAEYFYPFZXrkLU3FONcYZVLl0dG5U+pZLbNPMnKa9DXHAJjSw5A1mmgWATT+yMNu0EYjm0gHoL0ffJro8XArH0A6RhEGeXdP2D8+lFTaWGmZc3HAl11rL0qyNLL0CWL3gCP51tNm84O/gkBlQAAAHIBnyxqQn8AA+LwFKnsh18j2GdzeE+L9vjQBxL32DwDslLpalR/GMMJr/Emj7M8evcWE8T1Zb9jg9wSJ1W5HCwiI8neQ3PYmTiDN4B3rjJkHZ4xiNwx0C7pcn4hPdujL/H65OFH5IhdKzYssGGBq/wmZUEAAADHQZsxSahBbJlMCG///qeEAAAGbd3QFAK9CSoL4ASMat1v7xedUlxO+NYBnWOGLnvbT1vvVTwoykOQSxseqUTr57SdyUr1fStywwOmKqGAEwT5xp4sdweYoid6YtKpcXWEfc0i5DPXqNgVyAEdXp/GWex0jk5Am/qVUNuYl9ZnbsAB448j3EnwRaj+dA6TWarENpfi7Gr2joqvrS1gSAd345qihkzkRZRFh0Zffc6s9mvjIRP9ycdBBV66TLYIBMWC6w+1xuiggQAAAGVBn09FFSwr/wARYMyh4jVYsxsjxg3rglalTqtY5Ct0np4lJaP43H/dwGorllypULPiHcE2/s5FEUzRH7Y8mGSFiCS9oAZ5uwEcHWGgRdkbHgaYOQFPxH+nr2/GwrtbfXPc7SBbQQAAAFgBn250Qn8AA+GvpB86/sZH3wrzeUBVkVU574AoBMkwLMLUN6IzfXembHUJxi4mF7hYRcw//q9/8cTaH2NTxpQpy0gV3VzmxRVulagTL/NQX4C2zYOAEyFTAAAAhwGfcGpCfwAD4vAUqeyHXyPYZz4/aq7PIAJarlkf0I8EuYFRyNzAv6zCjs+XcOkIAbWqcD5TR9lR7oT+jAHfceaJ7PnKmU1Dv54PjmHKyaL+edBq53m5lMlnL2l772C8OwKYul8UKuA8WkLLAmvmO0Rag0BdYexehLxwWBRyjGd1wma3bkAj4AAAANdBm3VJqEFsmUwIb//+p4QAAAZxB+1J5Lgqw1ICIcEOHjXbM31sl6IpgRFXetwH92QbYrH01fL9sejWKvZt7AoKUTR8d6tsL/4pR6j4SQg22vdVBNDpJr6wktBu0Pvp+pCLImuvMj9SmU5GkSyAyyXBfCibD9aUVBniA+DFApA8hK4hdOD6L3Wl4jn/ku+/KcXYVDuMmaYldcCJx/lTeSnMTkHBCXc/HuhohvbbbWjsE56oTfAZJYgj3Hwf+sj9A1qbcNE7QG5pA5EmXPps1NBJ8MEyGJXg/wAAAG9Bn5NFFSwr/wARYMyh4jVYsxsjxg3rhfo1I2x25rt0/ndAEaqKccm2d7E3o5X5HzBFXWFoylDsn8q1wIt95yuAoAbAX0uynCuPaghgV896Ci6id5RY1cFLcBeQQO3o+vNNHO/IHGKaVku0IOdmjYAAAACCAZ+ydEJ/AAPhr6QfOv7GR98NnynZDR8GGCpEAVJ7G/bn4yEjR1TOAkStxJ4YuHFLJ+hMTlTPg17VbqMEWOsm6HPUHHbOCw2L7gwOIkYP3N/kOXjKYrKHOfjd4Tza5mSNFO5r/z05WE64r04Dar7dyP3MxGjMzFGJm09KZGoTqEK2YAAAAIQBn7RqQn8AA+LwFKnsh18j2GjGMxFGaJi+SEAC/2PMzMvi70zPSkvaPAKRWDp3yflW3+L6NxL0DvUyz62fv2obGg1w9dfLfU/jmoqdGTq3DiHIjgNose8LS4tnPppbzU60mjSx20knZ/H7Im0sNk70PjM5R3/Q21MBMHahfgJI7yqcIb8AAACzQZu5SahBbJlMCG///qeEAAAGd4TzJYib1JvvmsEazEEnQFQBZQDy8emWhAuSRED38pO7ClHWxgJ6jSjsZkcjVtk/veQW8g/KUZD+MCWZoZqa5I/SrVhAaZMBPAgHsJEsFqpXDjq6dksQbP8wEJI0e5SvGZSV6ezk0BmkCbdFFZvqLEbEL0xwK2e+sTkQg7hrKEA/5o4FnU//PdcCf2NDvGV6yhyLHInMBrcovZFe/pxCy9gAAABsQZ/XRRUsK/8AEWDMoeI1WLMbI8YN64X6MdwhO1mxW77j6N4I/iVACWgxfE+JbTGALjQmFtZ6QtG4m+i9vGfKvV1P3Rfum/gWQg9S19xFaeNnp4vfoiImnjR7BDP1B6UKuhMxsGiPEn8xAGLBAAAAdAGf9nRCfwAD4a+kHzr+xkffDznYgSaOa2z0TPK/5j45VQbueKO2iQtEzocn+ZQBEx0xcvEKhEzDh87Fc1oTVLWos4gGUa/CIEnB0qo5FPrOShpNeR3K2VxuWUFDDaJzszZpkcBhhmfGvqWHCsX39eiowDQhAAAAbAGf+GpCfwAD4vAUqeyHXyPYaRhtFqlvvTuLRp/lGyJx2jXYABag9Q5PK0tObGDGZAsi9xAMMWGOQ9wfVXx32/TotCNZMuuFCBZRHO+VMeYU8yyh1ZOWiENnBYpqABpTBHX1J8VZ2b4J0NT9dwAAANNBm/1JqEFsmUwIb//+p4QAAAZu1C08Dva8cIATQjXTw/CQg9JW3StzGzKmDnukoY+OzPb4lqJI0noMCL+HqVh58k/HPk/0ONCG7IgfNBPnDsqFXB2+s8GISP8XdrRk8eXx6zfw11GdCH/POU/4hGh+iMZnwl/OqFdch1aslkwQCzSnQwI5G/vYb4GDRqmyKshGHBkjEoGBFP7I981L8//eO1/Ik3EBQyk8FdaWxMFaQsmy4awXjkz58sY0izC8o6yCpjZYAClssnxKaPzU6PHrOqKDAAAAkEGeG0UVLCv/ABFgzKHiNVizGyPGDeuGxk2WYN3V2Pt5XkQgBXEvUuFFPyZ6OWffh2oXkSFqyttFFqAtq7LXS/8CstcogO2EsKlPxQUNMmrpRDvBtAvE31WAJDTxEuDuNiBcJ/zxPjyA8lyqV5TDTNmP9ExJ1aLDc4JPp/vszBXg2069dAGnqYbmg0NBdejWUAAAAFwBnjp0Qn8AA+GvpB86/sZH3w85mYENGRAyadhyd+hYNwAmTuZC9zA9XUwtGvaiV/MBTxWEsMWUTEfXihaXVc4ShhDGd/YQujGnIgB1q8SZ8HX/u4aVZL3etjAk7QAAAHABnjxqQn8AA+LwFKnsh18j2Gkaxo1fogBMpJzqc36m6kHSpx47T2tMKX4aCAglKKwd1jhM+nfuCyWk6M60uuw3QvZU0opX7HY4ooMUjTs5ZpMf+jN2MKBGTZ3oPGAo5ZB6HSA+rsx4e7wjQxZswBSRAAAAzEGaIUmoQWyZTAhv//6nhAAAAwJ7ktavsgE19RX5d7sCU2XPqkCHgwKAHtPU/F64ILl3FpQAyOrwnFgVwuR1uV3yC5+lg93jrhXb1d9EIABEQFww2lku0JeC1ZZ1IhwO1pw4K0GnZKhdOMrzZ21y6IixSroT59fHBsoptWmJwLsnv3mjKkZEhM2trU10gYvH8mduiFdMGXlEqMZakr+xqTlDL6dPyHCPcM0n4oUQ/rZ1sIZBDwddmXnXjZRNC1d+KJniHVNQVT6QxzdBgwAAAIdBnl9FFSwr/wARYMyh4jVYsxsjxg3rhr0YPrDoQsr3hhyIZRTWHCVBtDJACvh7uFgGp1tCWl+LvYucfsKL5NazyS6BkZFOKnZu7XWWTWrZKmvUu0J7NgJDm5H/0t+4KsD6KiflPyGd8QEIAGtH17GXTSsXqRoDvKttmn8JX1b0+9A7MwyiCtgAAAB7AZ5+dEJ/AAPhr6QfOv7GR98PQlnqQlDFkZWa1Rbr28HAAM/I7bcEhCaUDA4sJvUkSxxdsLtQBXMwV9s+6ispQklk+uUwuMhbW7qjQwQ08iK3hkxi+i8UEC5R8uqYRUlj/FCTnHCL+7j0nH1DE+ri4Le9fhGV3Te8JJUxAAAAXgGeYGpCfwAD4vAUqeyHXyPYaRsVJ3NlTls87YlAYdaNu1sTM2E3QYsCCmv1tY7eNBqvwrlfU67qOSzZgGUVm2uIVwPx0UnWs12mJjPwDlh5K1hIB37viQIuWMFKFTAAAACOQZplSahBbJlMCG///qeEAAADAnuQqy8uGuOABJHKLRFui/k8Ithh8G5m6fYlAYtudU8pC3cqoTZ9SzCAGqXY0sXr4CFjcUhMdBwmhXOGH9PkCN98lvg+67hmISsULwpsNKp/XOo5my7Qi12y8QcJuc6OdGC6th32w25f+kKajGIHFEOAjcJVu0J49epSQQAAAHtBnoNFFSwr/wARYMyh4jVYsxsjxg3rhr1ccaWlgB0G4YkAvNXzf5Pq6wO/hRUpestQ3l5cHNPb+L1c44ZaVGhYWzQy2AZanfMTu+G2kGdpd2rtg+fDKz19mV5V2M6i0OsFy7SzEwz/+KM/Kj7YhE6Y7qhzK63+R/gkzPgAAABTAZ6idEJ/AAPhr6QfOv7GR98PQsL6RhGTszr16d7dubn0MTZjehVbZok09WgCDvAKqiFCrKLFKzqAGXObUXulMPCusXu3Ltq1qhZr97z/5jsPI9MAAABWAZ6kakJ/AAPi8BSp7IdfI9hpGxfJhpOac5kmVF18WlB8z6ImugqVLSY0pq/v8zgDpGai0eH+bIeK6xp4pCQSWnEL+UA5Yp3q06dYIB4NiXvDhyh1WzEAAAB9QZqpSahBbJlMCG///qeEAAADAn/Mu0c3tMGFZA0AOB91gCZIu0gVU2f5+fuf6hrRVc5KLj01Bn+QmVDAX6vasqFPXHIqiTv5GYMS4iDu2TDoRdt0AauxesCgDKLIPyDXTtYQtovORUev1BDLuQY/tfgwomI52IJZQOIC448AAABlQZ7HRRUsK/8AEWDMoeI1WLMbI8YN64a9SrGOZdqk0V+vyH7dv9RcwfAHgvmgBqj5KyuPBXHuut6E3n8J1lfUVtvmP9dOygVrBhQJ/fjzt5rKaMnpgR3awLMVmFeW+iMQxJn2IekAAABLAZ7mdEJ/AAPhr6QfOv7GR98PQpwRcNnJtTV6Awr74APL4kAc8lq0wv7XMdV9yIH1EIewUIEe0CzLm5IrMHq3Ub6OPPAc7BNv/uPuAAAAUAGe6GpCfwAD4vAUqeyHXyPYaRp+fL5MPxiLUQhU5GNxqrRRcaGXC15Vz3JoArUxjNLt3I2UN23OYdYA67dAvTCj/hEjZPAxjFCqGCsWoBHwAAAAx0Ga7UmoQWyZTAhv//6nhAAAAwDt8p43t1BsAqAEqgNh0ovAe8Tw2gDIXbmbn3K9RlxuDnIxtmB7L/hOKuJ8qj4lzsD9afeBma3bL1xv9Y2w3FAY8QZIkJNrQp1h3GPQoEEMxROIQl2X84ebIjRBcrdZyc2pdrCmFVkoiUvOD7wSbl4ze3qI57iCY69NTPkKoR4Y197QSx2TgzSkT1QrZPs/3bYxgSdWtQOqd4KpcxBHbMjUzOw5IF8rAGVlTwQ91OTgkscRnTEAAABgQZ8LRRUsK/8AEWDMoeI1WLMbI8YN64a8SS+8yf6GJ/NOa886m+GMAHllClz72TtnNCnGduoc4JBXsB+E5nbOhLgpYT/lvIxERoId+XznKPGFacyoWwBPUBtVK+0iQArYAAAAWgGfKnRCfwAD4a+kHzr+xkffD0CD5jjYpLKIUnlQJT9R/uKAEs4+ZAVU35klbLCkvV1m7yThObMvJWDF7LcLqO2NfXt0LGeVm0GQWm9yMoPPgD6v3W37/CArYAAAAFgBnyxqQn8AA+LwFKnsh18j2GkafmRI+EHTjM6io5SsNeAC5u59cH6StEhuQxwG18VPh58ttrXKwnlGfYeuInIPwKkgEGia9Cs+iDwZBz9LjQfL9ijpIA45AAAA3kGbMUmoQWyZTAhv//6nhAAAAwDtBhU10QAUT2HPLdaZFuHNBv5rc5zrHKtThg6ZAF80RFgj3do9cp8ZQ5YLzh29FTc4CxbbCYIUMosH3h/hFemKue47smdajLJ2fjcNyjdu4DFCRxMtboEKZqAeNXtslvj9AiDyqTxe88AS4Qypt+zy3PXr+hr8SUnTjffP3CiuvVViZERVeu/jejxujZEp3+fXdMSTbSL02JF50xhhBblNYGopN/uJuPv5frIjSPTNclZV/KOPd+uQcIWFCpIQ4jsbWe+uXKRSbFaTcQAAAGtBn09FFSwr/wARYMyh4jVYsxsjxg3rhrxJQ369H2YqlT8IGURgI6m1FIAWrsVhLt+czxzizmMcYjgb/MvQjUcLj/nbHI6ay7WwRW4zmH0vVOlxNvqREjlCbEFo1XqCPlQAGQDkKSa7kZAakQAAAGMBn250Qn8AA+GvpB86/sZH3w9AgySuApPDBPzcbg0e7PzRPeC2fqAsQWuGoAmvEQ30liEv0DZ8FybAXokpT3aWJu9yV7tw7xMEi92WZlGX3mrJCDEveNF6aGA8e8qc2CkA44AAAABdAZ9wakJ/AAPi8BSp7IdfI9hpGn104RezkwAOK18wJkFElS49c9DSt7FaF7HTwFtm3+5inO1WpROYYkXrkNkwkKmB11Jnn4ZAHN+2y97nNVGda2ruVOCmf5+NICpgAAAA4EGbdUmoQWyZTAhv//6nhAAAAwDtBvYfGoAigJIU1uwTRCFI5UZv7QjaB65OEtgYKCkd2MQlEZbV3ScpKmy0e8cldXiX3z+BBl+YsdEDDzuZzxaNNsg66KvrdJwDkSjpPBGjLlNQPA4SX134roW5ImZbkLOoJoSZNunSuTDfQF1JZ4weGwtQc2to+evkmFFtseJfQ1Ly0NLxJ0nlh67KQ0wdr00VTHPsBWYoMCFFAvNAzXUh7mgnh1Z9uyEeLVDbk4t+KqP8DYdkLZTr8Ku+RN5IVpy7+Tm8u95+SMElTsFbAAAAdUGfk0UVLCv/ABFgzKHiNVizGyPGDeuGvElZak7XCH1WkASQH6Va/FamkxlLFc7T4KpIresroGcgfuC+GB9PW0y7pSxDUsyMTARCPA8SJ7ycXpr2f60SPbjX9nAyabLzjUA/Kv+ISN9WJkR/GVO5pOIS48AOuAAAAGYBn7J0Qn8AA+GvpB86/sZH3w9Ag+YvfnDAJ/AFBs/dki5fyUJHlYGI+vUQ3GDVApmaEoYFJVKCssEyki8XYz3FCN1DAZak/c69sZWMa+++k+XOnZeLlLz7hBq/1yKR+vRnjjZcBiwAAABnAZ+0akJ/AAPi8BSp7IdfI9hpGn5PxuPg3SKK4kBO6F0O9mmIPzax1mANuL9JzYXtY3fSebhNMQXv4UCkOyY78zpFmOC5LLbvCcX+S/OyO/LKT5EP2PypiXJmHUN4TSKKEgTYDgAWUQAAANJBm7lJqEFsmUwIb//+p4QAAAMA7n9H0L3FoXizUjemmFM23euI3B7ugY0WidOPwtbzh6f5+0+3O7ymTpM8GPH85pufVvw5ScHcXwQztujbyCv5NQaEs6ZdXxb7fj++NK5qJgYTZEmGV8ly/s6N7MXH+UkPgzjk+g9kM0nRHxr6Wb7tR2ZcCTkiLIfk508fuy8L6Z8YkTmb0F+13Po1Y05THOUlZgZjqPsNKtiFOP8iINWOuF2szJHga7uTEHYKs22XE/GIsd132GMk4VAEEy3YdMAAAAByQZ/XRRUsK/8AEWDMoeI1WLMbI8YN64a8SVkvtkCQTpxIyCuJbHygAEoFmk3fG0bWyIoJyI2Ee1WQRXwAhyo8hRzN+2LcaKSMKyTb+Pyf6O2RPh82t9tfJ84cCL4ACMUWl+4xQ/NZngRVKpfKkOA6wDehAAAAWgGf9nRCfwAD4a+kHzr+xkffD0CDpeprkRroPlZvYZWFGAB+4H6ND50g9c4KcynQtNbSIW3/O4CmRvZa2b2VaZtbzNyZDxueZ2MzTmAvg7OAx+gPIEqw0MAUkQAAAFEBn/hqQn8AA+LwFKnsh18j2Gkafk4FI5yXOs5bu3UxqvL0CADvp2QFFsd3s2CYMgBAAmk4YXTbrA+hW1wumFaPn3b51HTIFlMSTGwc2X0oAVMAAACpQZv9SahBbJlMCG///qeEAAADAOjwnmimbQkD5rQBDak6EH6s8ZZCzMHqtSBK2hB3se9N878lGVpp/e67F3sM6YqgJcVgTTgLGPAyJl4AJXQU3HEjEVv2Y2hWBEN1stc+2dNHZvasGd3sIru06spwHZDV5zRLrPg0ZvSwaS8mSK9nPDuqr7CgoiFiop+WVhrXMwac/wXRYCQTvv3ap4blzJCKSeRsL+BfjQAAAGhBnhtFFSwr/wARYMyh4jVYsxsjxg3rhrxJbfa7c8TKdSPf3NdHp12YAJQhCZh/XpsZGKsfR+yjrv1XgXrEqQ7Y772OOfJP2fZhuMLRRGHjD6jz9m2m3BP/fHJDHjRK9EorrRR8XYgOmAAAAF8Bnjp0Qn8AA+GvpB86/sZH3w9AHM/OPIsAKff+6Xhq44zG1h+u+AG67MOFmjFq+s82CuGWNGVxuecK0nPQ10BRcJvf1GQQu2rWp884MI8IUaRB8IEzX0LIMmHoWMBHwQAAAFUBnjxqQn8AA+LwFKnsh18j2GkaflZNimw1Zdq9EAl5/JHW7MC4ALBIN9fueEO/MaVuwxKaALlC3nfVJRDLj9aMMD0BPTPLNif1iBFHbbG0PHZW/yYtAAAAtkGaIUmoQWyZTAhv//6nhAAAAwDucJ5oQJQDAI2n8+vgCGLXZ3jR8Re6PyRp+fLe5+Li0lrvKC9z+fYnyN03faolkEJ2GUzMnAGkWOQ06Wo1KWpqEy+QvHdDRZ3gAzPDN8aMB5Lt4vjaeORuB1IZaZ0Ecp8XQbQ6qx3ptSqCsjZZFKmGGfrDBQy3N9LoOtGjaMuBOwpyvgmfX/hUCCYKtMb5pJ/pBmTaTmVKn/uMUTHbnGxQV5JGAAAATUGeX0UVLCv/ABFgzKHiNVizGyPGDeuGvEmV6aK6Hb/fl5E2YaqZp20yZuCCkRAQvH/7g8AG3dmsPEcUm48JosqFQt62jLNTHGtZQIOAAAAARgGefnRCfwAD4a+kHzr+xkffD0CC2iZrc/oApivGv+RB9DwBbT6xzDbtZzQt8mLDZPe8VSfZgu6CWXvUxYEsgz43gwYFxSUAAABCAZ5gakJ/AAPi8BSp7IdfI9hpGmFJD6/iFFENzaGBVevMiu+trqFqHhiAdBzxLWihNABylNY8ztrNK9SH6YWdwDVgAAAAzEGaZUmoQWyZTAhv//6nhAAAAwDo8J5opi+HULYmPh5DgAce6sD07MQ5cLhLKzk22QbCIKpC3Di5NFnUZfVmBQz/py2iMc7ZU7pu9hPBgs8bAFFA+vSYbVnaBMbNrOyJ6bwPEc5cmAsXEu2nYI8TK0nkvxgBGSdnjV9GG7TfipiZk4sbWvBvQY6zV2TcA4pGPvnZXMGJv+cwSH+ft0QfnVQw5VZDT6eAc0YgF2wv0Nms9oxdH/FysbeoyBFMnnfLakhfdYd17fwkYbaRMQAAAFpBnoNFFSwr/wARYMyh4jVYsxsjxg3rhrwbTeRK+yMvRGcr2bM8fbrHCqPc8xACtxcgkQJ7s7fVyE6eAga6AtTKWKVQ4DcO9DLaGlQEirQ3+PzbpQIJ4W/CARMAAABBAZ6idEJ/AAPhr6QfOv7GR98PQByN42SiFGX+lbpLs6LyOTWIxMOX24PlQAbuD1jRlW/z8kJso6LZArAm4GLIH+EAAABBAZ6kakJ/AAPi8BSp7IdfI9hpGmFJDn9F19dtUieTYf5KSqfyM4A20dy8lRtobdJosmC7iLpEkXMLjlSYkQN4ScEAAACvQZqpSahBbJlMCG///qeEAAADAFrD0XDBRHW+FNvQCEGAA06WM4ltIVxlyyhJ1Cleq+xispeGuOk9y2jrtCkNWfHVgm14TKIq82xCEF2jNNlIPpFabpAZ/bFCoGsgiD38JFJI5VSMDbtEhd3GUgQ/S3xRm76LxE3MM+gaXBkMif5DWKv6cWZINEoHE6A3iBSm5ortvzBjdJHj6s2VjzRgYgZamgsSrLGwEomhS8VDpwAAAF5BnsdFFSwr/wARYMyh4jVYsxsjxg3rhrwbpkXmWeBIsnjDW/RCwALRUvh1USXn1yAWXEphpkMqbHjAdch/LHKjN0fUQT1O7T6wLuDCAn41msQ36dJxZN1V3ooqgHHBAAAANwGe5nRCfwAD4a+kHzr+xkffD0AcjeUY85S5ZNO2z1mA/NSp/fLLgAW9utNALFAxn7v2kG+gCVgAAABUAZ7oakJ/AAPi8BSp7IdfI9hpGmDJCJvqIoK2GWsfHzK2cmgAWa/kWqs/FWETz5ay96Qxapqli/cqq1MxJ0p44NGr2H35npV/YiowcpFn8pwRTQH3AAAApEGa7UmoQWyZTAhv//6nhAAAAwBavNzXwixMIp/UACdBgSoD3c4xiHaTPWvJfntZfEoS0jo3aDZ1fQIlu2mCpZ9+uo3i+NwRaYn4P7ZNdC1mfVoVQUfH8Bl21tVEovkyrxqTTU/J4YQCM650RLcJHYQhONORckkJGsdCguN1LC6TN9VHxA2oL+QG07MswT2ThGLKQaJMlkilJvqwwohEgqv31qIHAAAAVUGfC0UVLCv/ABFgzKHiNVizGyPGDeuGvBumRfn+BHJ7UabqZ1gsUnkTbVcJNEnU0AF1HeKwePjIOEJ70nzC7lXPqoFA2fxucE2NpvW+tl2kK2IQHLAAAABBAZ8qdEJ/AAPhr6QfOv7GR98PQBy6Vv0LUgeg12h8DzuMnbfHIAWvngM0alofmeTBP5/QVYYNEv6ixhcjr2xAZ8AAAABHAZ8sakJ/AAPi8BSp7IdfI9hpGmFcUbC9Nx0UFrn3Yhb8QHl24AE7eL5+Goji7FUs21j5Ul9a9bVrwoyLE0eQDv2GYxPDcUkAAACZQZsxSahBbJlMCG///qeEAAADAFs5l2jm9t/J/gSartpvYAbKJFMKgaEO/lPrSlLyskEHT5S6daRTj9+BjgjAE7hpiG3gZM7noPBptKdgOrf3zS2Dep6X0nEWbMDS2ETLYHilK9gQ6hXCDsLoP+zch3UUxOgSxnHXGltVQI6+TbqbGO3YnGN2yPilrRBTPnXMA5RGN7v/g/m9AAAAPUGfT0UVLCv/ABFgzKHiNVizGyPGDeuGvBtrkvnjKOvvBcicjsluiJAqQAlsQLSx9R69hGncO+Nz3y5gMWEAAABFAZ9udEJ/AAPhr6QfOv7GR98PQBx7JFyqPvtH/SfagqbaSAEts62KtmJozF87nmwS6B9kpjZvA+outMPCJTG7uErVwF7AAAAAVQGfcGpCfwAD4vAUqeyHXyPYaRphRQGT4qwBQa4u5sK5eHaqr7L7cXmym3NxLuBOAQ93Q+SUdYCG6pxrt4ryc38SFYUoyaFzFzSGG10prZG3yDlgWUAAAACNQZt1SahBbJlMCG///qeEAAADAFs5l2jm9px3CRZtoAbINa3TNrlhsSA80jzFg2SqX1rqdLoMVxnXSvFCPazOZ0c2m1MOmop6D/LE7/NZEBqD0eY+Z5QA7ggcQ9ZDZh6AeUFo7ntRxGyji3I2GyAPQikkXSAF0XrtRaRi+S6ILWNPAg7aJQtvuxACUCqBAAAAVUGfk0UVLCv/ABFgzKHiNVizGyPGDeuGvBueumMHNBBrM9VCEqFtIAcbe92R88u06grvKsS8d2X8lr9EH5Q78ZuTqfKJ3qo0cM2/Srwe916cNFQAvYAAAAA/AZ+ydEJ/AAPhr6QfOv7GR98PQBx7Jj09njTwFlfoM3CqgATh8lvHCEG2yOrW0HpaMpEVOEUxlMbcS7nqkCygAAAAOwGftGpCfwAD4vAUqeyHXyPYaRpWuUY9xqNOUDIIS9DACZdAmN3JZgkRTe+qUq92JpEoSnpZipLEwKmBAAAAkkGbuUmoQWyZTAhv//6nhAAAAwAhneZhxn7FLQQPNcEACuAzsCzAiuQSypIYlRmB5wMrsVVLqYgL0l2den4TfdUehiYiujKM844brf4CAZEVS25+XdCz3v9y7lrQWEyMSzCBWd2OMNotmuA+1/wenD4erdXvFJnTwZnqZPAp+/E2R7BABjwjcngFbvXJ6n/Z+8IiAAAAXEGf10UVLCv/ABFgzKHiNVizGyPGDeuGvAq9Nkdfioh1Oa6qG8dOAE1X63RWTxV3WWY3BKdEnLohfGX44JTMSYy1A3F3FeM1EJjM91sh94KGRqlGlifesfJCRxUxAAAAQQGf9nRCfwAD4a+kHzr+xkffDz/3xijlcHX2gwMAE6zTvE1LlplFOdFCsYIUyp1IAyQoSg+wKHjBzZwhdwc50BAxAAAAOAGf+GpCfwAD4vAUqeyHXyPYaRpWuI/QqgZHIGsAE6hf+Zyr18OPnSa+kQ1iw/pf/OZH1OHXZA+YAAAAikGb/UmoQWyZTAhv//6nhAAAAwAhp+s1+oAiPiov6kCRhqHZAjRxGYQNyVrVgias6hrynR4PeNWcPIFMiSYLR+t/6ggKueVTkD6G7KTqSsY93RLA/CLULGgGoGMYGFxCBkfeM9mKeRIEMErY8oMoEbEHYNZyB/IFiszdW8fZLDp2ugA+Bpp5G16DgQAAAEdBnhtFFSwr/wARYMyh4jVYsxsjxg3rhrwKvSTnvWoAQp5Ho1DRbiIuG5pcRgoW3W71AJcHg6RSWF+5tD67WL0ndscTJIQD/AAAAC8Bnjp0Qn8AA+GvpB86/sZH3w8/9ykhYIDilM8HS4o9c2ilAgRJOIAOcO5d8XQBqQAAAD4BnjxqQn8AA+LwFKnsh18j2GkaYW6oIAtIuK0xitWvvrQ5F82kKrufoRISvPkNQ/bKUfQGGUMsaZSnnwCLgQAAANZBmiFJqEFsmUwIb//+p4QAAAMAItyD4LulAALpP+KyeD/oODkw7UTN3TsEUsUIVKFaEmK1+KhXAIyZ1mQzbgw9m1u8hd07bMHWE8kA10c7aCzPv+Znc/yehkkWJVUrkhCVwjMzhGIU/K3L++Mh2VbnFeX5BGn6srT13qkX6qJBeBrcA9oyLJKLTKZAgAN8YLY+J5XQYfYwowsLkQl7vNs75v3B1xTFidlbEic/TW9b+WdEEAMq9qeUch18S1csaCRai7ZGkb9pBnhfeygwtvV4GPYFXoOAAAAAUkGeX0UVLCv/ABFgzKHiNVizGyPGDeuGvAqzXob1+KgBM4gSu93WfV+KQHbudtcQ9NIiz0kYmEtjxLxzJ5gt/qnB766ZRG1peUjNuQEVo7bAb0AAAAA4AZ5+dEJ/AAPhr6QfOv7GR98PP/eeH0A9NIJooBHx3AiV1EWAB1fjaunp2d1Cg97I4vNiOiyAx4EAAAAsAZ5gakJ/AAPi8BSp7IdfI9hpGla5edJwxANIadc6s5Zm+sAhAButNCGIxYAAAADzQZplSahBbJlMCG///qeEAAADACLfA785bRAFAXTyzsYfGMvfIlrfr7X4FUbXshn/LQfsKBpPKKNXV1pkRCaL56NpzILLWze6tQkNEsBF9oDLHS+us/ayQT47qic2SD1b0JohoZ28YnFU5PSMjg29ckJcTtglkZFUPWPiEh07/6ukU5HRe+JefEQ1jm8SzhXepd9Sus32gGh3KvA4WzBNihPZIPfkHPfU5WVSIwgj9dAbBSkA9/K78iT41GQEiYh3aVdi3n2AEMIIkcJlppqf3Lt2TJsx5zc4XtD9g9V+ZFo+OrE6w0gu1Qj1cRuwRb+uUQfTAAAASkGeg0UVLCv/ABFgzKHiNVizGyPGDeuGvArKLIgGr4wAmmSMPStdc037/ZFIOXvINHrYehi8TYB891i0OrgmFAwNBVflUIYBgA7oAAAANwGeonRCfwAD4a+kHzr+xkffDz/3xn2/MoAWpKBlYLzEo4ZHOB0kLB6e7P+K2/RkA9SAGW2YA3sAAABPAZ6kakJ/AAPi8BSp7IdfI9hpGlaYNGwgACuhjQJBMgOGIO6VL6SUnOTpIafex2La3t5iXULZWg2a+9sBjqxt8QWbKP/Iz4xv0ES1LIAr4QAAAGVBmqlJqEFsmUwIb//+p4QAAAMAI6DIe9U88ACaefsWiJyEgaW2LSVXc8K23ULO0IWOpL2yuHst09Wm37cvxwTlKBN+1sdMNIzOVhZQLLbDBMckXCHs3Mkl1aBmtmQkrtf8hnLdMwAAAEhBnsdFFSwr/wARYMyh4jVYsxsjxg3rhrwKfCp6zBX8J9TqtwXlHmAWs7keKw/3fqGRO8D4I+M1LqbeGCjLxEWV1LMw0LnAPmEAAAA7AZ7mdEJ/AAPhr6QfOv7GR98PP/nDg4O3WdJKA3hNp8Acw6de2TA8Tzvyc6TUXHVoW8Is0Fc7KptgBowAAAAkAZ7oakJ/AAPi8BSp7IdfI9hpGlc+02JNrcnnj+I4hRxBQAJeAAAAn0Ga7UmoQWyZTAhv//6nhAAAAwAks+kOoAtwyEw1hMcoESFgRmH3xbShkk9RkSsXPi8JZpIEsGJzffdV77TFJ6/CKeg60YiCCQIR9FtNcmFMFd7BtWfLPrbDoUGU5qWmTrywhCyRjn2u5fSoS+JHXdMf2byAvIsyp2t5RNVKJBHTuLuCeq60hsHXThgiBdtVLUrrUVA38suoSwDl3GLZgQAAACtBnwtFFSwr/wARYMyh4jVYsxsjxg3rhrwLWkNFXepLBEV3NOfNAGQTiAdMAAAAIQGfKnRCfwAD4a+kHzr+xkffDz/4Y+lJpAwPdZsgWEB4QAAAACABnyxqQn8AA+LwFKnsh18j2GkaVpgu6FtZG2T6V8QOOQAAAGJBmzFJqEFsmUwIb//+p4QAAAMAUj2iylrRTioADpyh6tc0rVO1kGz8ewDhVK5BNvxD4flTpLYzHaUCBMSyGpcz1k67bM0XmY7SHhQjRga9t3gd6WxNrq/xlgKgxj2mrueXEQAAACRBn09FFSwr/wARYMyh4jVYsxsjxg3rhrwZGpL+pOFASPjAyoEAAAAbAZ9udEJ/AAPhr6QfOv7GR98PQBcEx5pS4ATsAAAAHAGfcGpCfwAD4vAUqeyHXyPYaRpWQJWj0skA3oAAAABZQZt1SahBbJlMCG///qeEAAADACG12CyMOoXkAKDdPyCOomvHQ9SwquFirRYdQcuzFx0FfR1lG7zEVoPR6lkE1AkSH8AiIZu9Pm5pmteIPkdGbWUOMDcUxtUAAAAiQZ+TRRUsK/8AEWDMoeI1WLMbI8YN64a8CfBXGN3wuNAXcAAAABsBn7J0Qn8AA+GvpB86/sZH3w8/9gtaj7W4BaQAAAAZAZ+0akJ/AAPi8BSp7IdfI9hpGlKdt/AD8wAAAFZBm7lJqEFsmUwIb//+p4QAAAMAIaGIaACgbkZGHjhHl3xMyJWHt+GnbqXM9HDaj2Lz7OQEFhz1uGZ3hG80W92D1LIJ731ACT8cxZEPs+Hvw8/MIjSJgAAAACBBn9dFFSwr/wARYMyh4jVYsxsjxg3rhrwEEHXoWjA9IQAAABgBn/Z0Qn8AA+GvpB86/sZH3w8/6SFgBd0AAAAbAZ/4akJ/AAPi8BSp7IdfI9hpGlKdj9dn2QIeAAAATkGb/UmoQWyZTAhv//6nhAAAAwAhwXPCFXLByoWhd/r/TaAQREiD2OAWeKD3OJ4h0Eg+pqFGzkH4GtkVxHFV0KU3MIK95KP/BzKIUeIzIQAAAB9BnhtFFSwr/wARYMyh4jVYsxsjxg3rhrwEEHZOACqgAAAAHAGeOnRCfwAD4a+kHzr+xkffDz/3PIhTwEJgBd0AAAAYAZ48akJ/AAPi8BSp7IdfI9hpGlKdWAFNAAAAR0GaIUmoQWyZTAhv//6nhAAAAwAhtXffAIPypncI9Xv3ImH+E4VxBwHn0YHgnc2/9mQTiASpmYBuOL4R21hY0ASXInfYMHdAAAAAIUGeX0UVLCv/ABFgzKHiNVizGyPGDeuGvAQQdnD5HkBFwAAAABoBnn50Qn8AA+GvpB86/sZH3w8/6SJPLNACmwAAABgBnmBqQn8AA+LwFKnsh18j2GkaUp1YAU0AAAAYQZplSahBbJlMCG///qeEAAADAAADANSBAAAAHUGeg0UVLCv/ABFgzKHiNVizGyPGDeuGvAQQQAFJAAAAGAGeonRCfwAD4a+kHzr+xkffDz/pIWAF3QAAABgBnqRqQn8AA+LwFKnsh18j2GkaUp1YAU0AAAAYQZqpSahBbJlMCG///qeEAAADAAADANSBAAAAHUGex0UVLCv/ABFgzKHiNVizGyPGDeuGvAQQQAFJAAAAGAGe5nRCfwAD4a+kHzr+xkffDz/pIWAF3AAAABgBnuhqQn8AA+LwFKnsh18j2GkaUp1YAU0AAAAYQZrtSahBbJlMCG///qeEAAADAAADANSBAAAAHUGfC0UVLCv/ABFgzKHiNVizGyPGDeuGvAQQQAFJAAAAGAGfKnRCfwAD4a+kHzr+xkffDz/pIWAF3AAAABgBnyxqQn8AA+LwFKnsh18j2GkaUp1YAU0AAAAXQZsxSahBbJlMCGf//p4QAAADAAADAz8AAAAdQZ9PRRUsK/8AEWDMoeI1WLMbI8YN64a8BBBAAUkAAAAYAZ9udEJ/AAPhr6QfOv7GR98PP+khYAXcAAAAGAGfcGpCfwAD4vAUqeyHXyPYaRpSnVgBTQAAABdBm3VJqEFsmUwIX//+jLAAAAMAAAMDQwAAAB1Bn5NFFSwr/wARYMyh4jVYsxsjxg3rhrwEEEABSQAAABgBn7J0Qn8AA+GvpB86/sZH3w8/6SFgBdwAAAAYAZ+0akJ/AAPi8BSp7IdfI9hpGlKdWAFNAAAAF0GbuEmoQWyZTAhP//3xAAADAAADAB6QAAAAHUGf1kUVLCv/ABFgzKHiNVizGyPGDeuGvAQQQAFJAAAAGAGf92pCfwAD4vAUqeyHXyPYaRpSnVgBTQAADrdtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAgbAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAN4XRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAgbAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAACWAAAAZAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAIGwAAAQAAAEAAAAADVltZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADwAAAHyAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAA0EbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAMxHN0YmwAAACwc3RzZAAAAAAAAAABAAAAoGF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAACWAGQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAA2YXZjQwFkAB7/4QAZZ2QAHqzZQJgz5eEAAAMAAQAAAwA8DxYtlgEABmjr48siwP34+AAAAAAUYnRydAAAAAAAAGu8AABrvAAAABhzdHRzAAAAAAAAAAEAAAD5AAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAHuGN0dHMAAAAAAAAA9QAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAPkAAAABAAAD+HN0c3oAAAAAAAAAAAAAAPkAAAgwAAAAfQAAAFAAAAAtAAAALQAAAGcAAAAmAAAAYgAAADMAAAArAAAAKQAAAHUAAAA3AAAAJQAAACoAAACXAAAAOwAAACQAAAAtAAAAtQAAADgAAAAvAAAAJQAAAKUAAABCAAAAMAAAACkAAAC+AAAAOQAAACsAAADsAAAAVwAAAEsAAABIAAAA0wAAAHEAAAA5AAAAUwAAAQIAAAB2AAAATAAAAGgAAAERAAAAfwAAALcAAACmAAAAmgAAAJEAAAEKAAAAjAAAAJMAAAD0AAAAqwAAAI0AAACVAAAA4QAAAI0AAACNAAAAxgAAAI8AAAB/AAAAhAAAALwAAABzAAAAfwAAAHAAAADCAAAAjQAAAGgAAABwAAAApQAAAH4AAADMAAAAdwAAAHcAAABsAAAA2wAAAGYAAABXAAAAXwAAAMAAAABkAAAAawAAAHYAAAD1AAAAoAAAAG4AAACAAAAA2wAAAIAAAACFAAAAfQAAAOQAAAC0AAAAmwAAAH4AAADbAAAAbwAAAOAAAACPAAAAgwAAAIsAAAC/AAAAiQAAAHMAAACQAAAA2gAAAI4AAACNAAAAdgAAAMsAAABpAAAAXAAAAIsAAADbAAAAcwAAAIYAAACIAAAAtwAAAHAAAAB4AAAAcAAAANcAAACUAAAAYAAAAHQAAADQAAAAiwAAAH8AAABiAAAAkgAAAH8AAABXAAAAWgAAAIEAAABpAAAATwAAAFQAAADLAAAAZAAAAF4AAABcAAAA4gAAAG8AAABnAAAAYQAAAOQAAAB5AAAAagAAAGsAAADWAAAAdgAAAF4AAABVAAAArQAAAGwAAABjAAAAWQAAALoAAABRAAAASgAAAEYAAADQAAAAXgAAAEUAAABFAAAAswAAAGIAAAA7AAAAWAAAAKgAAABZAAAARQAAAEsAAACdAAAAQQAAAEkAAABZAAAAkQAAAFkAAABDAAAAPwAAAJYAAABgAAAARQAAADwAAACOAAAASwAAADMAAABCAAAA2gAAAFYAAAA8AAAAMAAAAPcAAABOAAAAOwAAAFMAAABpAAAATAAAAD8AAAAoAAAAowAAAC8AAAAlAAAAJAAAAGYAAAAoAAAAHwAAACAAAABdAAAAJgAAAB8AAAAdAAAAWgAAACQAAAAcAAAAHwAAAFIAAAAjAAAAIAAAABwAAABLAAAAJQAAAB4AAAAcAAAAHAAAACEAAAAcAAAAHAAAABwAAAAhAAAAHAAAABwAAAAcAAAAIQAAABwAAAAcAAAAGwAAACEAAAAcAAAAHAAAABsAAAAhAAAAHAAAABwAAAAbAAAAIQAAABwAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguNzYuMTAw\" type=\"video/mp4\">\n",
              "    </video>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}